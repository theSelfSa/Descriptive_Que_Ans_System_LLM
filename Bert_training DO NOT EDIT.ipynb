{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert_training DO NOT EDIT.ipynb","provenance":[{"file_id":"1u5oB7YfuU46eEPAFWSauBj7vB4EPB_9k","timestamp":1617195457067},{"file_id":"1ROdTuQ1XE2SF5nSHPs9cKI9tKWm5nEFB","timestamp":1616558841560},{"file_id":"1NyXudKiDcASC3o4e-y9C-7SjgkOyIrn4","timestamp":1616481610188},{"file_id":"1_PM-wzSikHYs_BRxMBmsLFn2BIVbQuh6","timestamp":1616480710042},{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1616469862208}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6ENhtoHQHDWv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616497146771,"user_tz":-330,"elapsed":7642,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"42b90712-a7c3-4791-ab00-74ed8cf40ea1"},"source":["# verify GPU availability\n","import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sm5BGq-gH4mr","executionInfo":{"status":"ok","timestamp":1616497154953,"user_tz":-330,"elapsed":6271,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"57416644-4d7d-4b77-e0b7-adbd31020bfe"},"source":["!pip install --upgrade pip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pip\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 5.6MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 19.3.1\n","    Uninstalling pip-19.3.1:\n","      Successfully uninstalled pip-19.3.1\n","Successfully installed pip-21.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PpyQHcAc0xKT","colab":{"base_uri":"https://localhost:8080/","height":307},"executionInfo":{"status":"ok","timestamp":1616486988120,"user_tz":-330,"elapsed":3254,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"0ed7abb5-47a7-4724-c7b1-0c34c3a1db22"},"source":["!pip install urllib3==1.25.4`"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting urllib3==1.25.4\n","  Downloading urllib3-1.25.4-py2.py3-none-any.whl (125 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 44.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 8.1 MB/s \n","\u001b[?25hInstalling collected packages: urllib3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed urllib3-1.25.4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oT6hO4xXH69j","executionInfo":{"status":"ok","timestamp":1616497170168,"user_tz":-330,"elapsed":11480,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"78184f9a-4145-49ef-f550-0a962ac962bd"},"source":["!pip install pytorch-pretrained-bert pytorch-nlp pytorch_transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 4.5 MB/s \n","\u001b[?25hCollecting pytorch-nlp\n","  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 3.9 MB/s \n","\u001b[?25hCollecting pytorch_transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[K     |████████████████████████████████| 176 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-nlp) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Collecting boto3\n","  Downloading boto3-1.17.34-py2.py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.0+cu101)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 6.5 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n","\u001b[K     |████████████████████████████████| 883 kB 18.9 MB/s \n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.6-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 1.2 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.21.0,>=1.20.34\n","  Downloading botocore-1.20.34-py2.py3-none-any.whl (7.3 MB)\n","\u001b[K     |████████████████████████████████| 7.3 MB 23.8 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n","\u001b[K     |████████████████████████████████| 153 kB 51.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.34->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.34->boto3->pytorch-pretrained-bert) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 57.5 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=92c5dddd3f6940a1703daf78018e8a160dfcb1907d17c1c51b5756195d29dc37\n","  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n","Successfully built sacremoses\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers, pytorch-pretrained-bert, pytorch-nlp\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.17.34 botocore-1.20.34 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.2.0 s3transfer-0.3.6 sacremoses-0.0.43 sentencepiece-0.1.95 urllib3-1.25.11\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"RvPtUkCG0vWg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nMUbI4fH9vq"},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import io\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# BERT imports\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n","from pytorch_transformers import BertTokenizer, BertConfig, BertModel\n","from pytorch_transformers import AdamW, BertForQuestionAnswering\n","from tqdm import tqdm, trange\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QmAxmTgbIH80","executionInfo":{"status":"ok","timestamp":1616497182194,"user_tz":-330,"elapsed":762,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"0426c7e5-7f1e-4ed0-e04f-6ab5eeefd408"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yE4U5f9jILwa","executionInfo":{"status":"ok","timestamp":1616497204014,"user_tz":-330,"elapsed":20625,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"e64baa2d-0378-4642-c3b2-e23ca7a4bd2c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjNKBnFZIOsa","executionInfo":{"status":"ok","timestamp":1616497205701,"user_tz":-330,"elapsed":736,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"0c3f90b8-77d8-4272-887c-0a2f232b91de"},"source":["!ls /content/drive/MyDrive/Final-project/data      #sem_7_project/data/version2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Bertprediction\t      csv\t\t  dict_embeddings1.pickle\n","cache_train_new_25gb  dev-v1.1.json\t  dict_embeddings2.pickle\n","cache-train-store     dev-v2.0.json\t  train-v1.1.json\n","cache_validation      dev-v2.0Short.json  train-v2.0.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUe_Tx2KIY3b","executionInfo":{"status":"ok","timestamp":1616497208865,"user_tz":-330,"elapsed":1666,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"efbeb436-8c13-4b07-a724-f2be6eb88e65"},"source":["%cd /content/drive/MyDrive/Final-project/data  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Final-project/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qHD3_LfqIeQX"},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Final-project/data')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnJpEcseImmK"},"source":["\"\"\" Official evaluation script for SQuAD version 2.0.\n","    Modified by XLNet authors to update `find_best_threshold` scripts for SQuAD V2.0\n","In addition to basic functionality, we also compute additional statistics and\n","plot precision-recall curves if an additional na_prob.json file is provided.\n","This file is expected to map question ID's to the model's predicted probability\n","that a question is unanswerable.\n","\"\"\"\n","import argparse\n","import collections\n","import json\n","import numpy as np\n","import os\n","import re\n","import string\n","import sys\n","\n","class EVAL_OPTS():\n","  def __init__(self, data_file, pred_file, out_file=\"\",\n","               na_prob_file=\"na_prob.json\", na_prob_thresh=1.0,\n","               out_image_dir=None, verbose=False):\n","    self.data_file = data_file\n","    self.pred_file = pred_file\n","    self.out_file = out_file\n","    self.na_prob_file = na_prob_file\n","    self.na_prob_thresh = na_prob_thresh\n","    self.out_image_dir = out_image_dir\n","    self.verbose = verbose\n","\n","OPTS = None\n","\n","def parse_args():\n","  parser = argparse.ArgumentParser('Official evaluation script for SQuAD version 2.0.')\n","  parser.add_argument('data_file', metavar='data.json', help='Input data JSON file.')\n","  parser.add_argument('pred_file', metavar='pred.json', help='Model predictions.')\n","  parser.add_argument('--out-file', '-o', metavar='eval.json',\n","                      help='Write accuracy metrics to file (default is stdout).')\n","  parser.add_argument('--na-prob-file', '-n', metavar='na_prob.json',\n","                      help='Model estimates of probability of no answer.')\n","  parser.add_argument('--na-prob-thresh', '-t', type=float, default=1.0,\n","                      help='Predict \"\" if no-answer probability exceeds this (default = 1.0).')\n","  parser.add_argument('--out-image-dir', '-p', metavar='out_images', default=None,\n","                      help='Save precision-recall curves to directory.')\n","  parser.add_argument('--verbose', '-v', action='store_true')\n","  if len(sys.argv) == 1:\n","    parser.print_help()\n","    sys.exit(1)\n","  return parser.parse_args()\n","\n","def make_qid_to_has_ans(dataset):\n","  qid_to_has_ans = {}\n","  for article in dataset:\n","    for p in article['paragraphs']:\n","      for qa in p['qas']:\n","        qid_to_has_ans[qa['id']] = bool(qa['answers'])\n","  return qid_to_has_ans\n","\n","def normalize_answer(s):\n","  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","  def remove_articles(text):\n","    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n","  def white_space_fix(text):\n","    return ' '.join(text.split())\n","  def remove_punc(text):\n","    exclude = set(string.punctuation)\n","    return ''.join(ch for ch in text if ch not in exclude)\n","  def lower(text):\n","    return text.lower()\n","  return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def get_tokens(s):\n","  if not s: return []\n","  return normalize_answer(s).split()\n","\n","def compute_exact(a_gold, a_pred):\n","  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n","\n","def compute_f1(a_gold, a_pred):\n","  gold_toks = get_tokens(a_gold)\n","  pred_toks = get_tokens(a_pred)\n","  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","  num_same = sum(common.values())\n","  if len(gold_toks) == 0 or len(pred_toks) == 0:\n","    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","    return int(gold_toks == pred_toks)\n","  if num_same == 0:\n","    return 0\n","  precision = 1.0 * num_same / len(pred_toks)\n","  recall = 1.0 * num_same / len(gold_toks)\n","  f1 = (2 * precision * recall) / (precision + recall)\n","  return f1\n","\n","def get_raw_scores(dataset, preds):\n","  exact_scores = {}\n","  f1_scores = {}\n","  for article in dataset:\n","    for p in article['paragraphs']:\n","      for qa in p['qas']:\n","        qid = qa['id']\n","        gold_answers = [a['text'] for a in qa['answers']\n","                        if normalize_answer(a['text'])]\n","        if not gold_answers:\n","          # For unanswerable questions, only correct answer is empty string\n","          gold_answers = ['']\n","        if qid not in preds:\n","          print('Missing prediction for %s' % qid)\n","          continue\n","        a_pred = preds[qid]\n","        # Take max over all gold answers\n","        exact_scores[qid] = max(compute_exact(a, a_pred) for a in gold_answers)\n","        f1_scores[qid] = max(compute_f1(a, a_pred) for a in gold_answers)\n","  return exact_scores, f1_scores\n","\n","def apply_no_ans_threshold(scores, na_probs, qid_to_has_ans, na_prob_thresh):\n","  new_scores = {}\n","  for qid, s in scores.items():\n","    pred_na = na_probs[qid] > na_prob_thresh\n","    if pred_na:\n","      new_scores[qid] = float(not qid_to_has_ans[qid])\n","    else:\n","      new_scores[qid] = s\n","  return new_scores\n","\n","def make_eval_dict(exact_scores, f1_scores, qid_list=None):\n","  if not qid_list:\n","    total = len(exact_scores)\n","    return collections.OrderedDict([\n","        ('exact', 100.0 * sum(exact_scores.values()) / total),\n","        ('f1', 100.0 * sum(f1_scores.values()) / total),\n","        ('total', total),\n","    ])\n","  else:\n","    total = len(qid_list)\n","    return collections.OrderedDict([\n","        ('exact', 100.0 * sum(exact_scores[k] for k in qid_list) / total),\n","        ('f1', 100.0 * sum(f1_scores[k] for k in qid_list) / total),\n","        ('total', total),\n","    ])\n","\n","def merge_eval(main_eval, new_eval, prefix):\n","  for k in new_eval:\n","    main_eval['%s_%s' % (prefix, k)] = new_eval[k]\n","\n","def plot_pr_curve(precisions, recalls, out_image, title):\n","  plt.step(recalls, precisions, color='b', alpha=0.2, where='post')\n","  plt.fill_between(recalls, precisions, step='post', alpha=0.2, color='b')\n","  plt.xlabel('Recall')\n","  plt.ylabel('Precision')\n","  plt.xlim([0.0, 1.05])\n","  plt.ylim([0.0, 1.05])\n","  plt.title(title)\n","  plt.savefig(out_image)\n","  plt.clf()\n","\n","def make_precision_recall_eval(scores, na_probs, num_true_pos, qid_to_has_ans,\n","                               out_image=None, title=None):\n","  qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n","  true_pos = 0.0\n","  cur_p = 1.0\n","  cur_r = 0.0\n","  precisions = [1.0]\n","  recalls = [0.0]\n","  avg_prec = 0.0\n","  for i, qid in enumerate(qid_list):\n","    if qid_to_has_ans[qid]:\n","      true_pos += scores[qid]\n","    cur_p = true_pos / float(i+1)\n","    cur_r = true_pos / float(num_true_pos)\n","    if i == len(qid_list) - 1 or na_probs[qid] != na_probs[qid_list[i+1]]:\n","      # i.e., if we can put a threshold after this point\n","      avg_prec += cur_p * (cur_r - recalls[-1])\n","      precisions.append(cur_p)\n","      recalls.append(cur_r)\n","  if out_image:\n","    plot_pr_curve(precisions, recalls, out_image, title)\n","  return {'ap': 100.0 * avg_prec}\n","\n","def run_precision_recall_analysis(main_eval, exact_raw, f1_raw, na_probs, \n","                                  qid_to_has_ans, out_image_dir):\n","  if out_image_dir and not os.path.exists(out_image_dir):\n","    os.makedirs(out_image_dir)\n","  num_true_pos = sum(1 for v in qid_to_has_ans.values() if v)\n","  if num_true_pos == 0:\n","    return\n","  pr_exact = make_precision_recall_eval(\n","      exact_raw, na_probs, num_true_pos, qid_to_has_ans,\n","      out_image=os.path.join(out_image_dir, 'pr_exact.png'),\n","      title='Precision-Recall curve for Exact Match score')\n","  pr_f1 = make_precision_recall_eval(\n","      f1_raw, na_probs, num_true_pos, qid_to_has_ans,\n","      out_image=os.path.join(out_image_dir, 'pr_f1.png'),\n","      title='Precision-Recall curve for F1 score')\n","  oracle_scores = {k: float(v) for k, v in qid_to_has_ans.items()}\n","  pr_oracle = make_precision_recall_eval(\n","      oracle_scores, na_probs, num_true_pos, qid_to_has_ans,\n","      out_image=os.path.join(out_image_dir, 'pr_oracle.png'),\n","      title='Oracle Precision-Recall curve (binary task of HasAns vs. NoAns)')\n","  merge_eval(main_eval, pr_exact, 'pr_exact')\n","  merge_eval(main_eval, pr_f1, 'pr_f1')\n","  merge_eval(main_eval, pr_oracle, 'pr_oracle')\n","\n","def histogram_na_prob(na_probs, qid_list, image_dir, name):\n","  if not qid_list:\n","    return\n","  x = [na_probs[k] for k in qid_list]\n","  weights = np.ones_like(x) / float(len(x))\n","  plt.hist(x, weights=weights, bins=20, range=(0.0, 1.0))\n","  plt.xlabel('Model probability of no-answer')\n","  plt.ylabel('Proportion of dataset')\n","  plt.title('Histogram of no-answer probability: %s' % name)\n","  plt.savefig(os.path.join(image_dir, 'na_prob_hist_%s.png' % name))\n","  plt.clf()\n","\n","def find_best_thresh(preds, scores, na_probs, qid_to_has_ans):\n","  num_no_ans = sum(1 for k in qid_to_has_ans if not qid_to_has_ans[k])\n","  cur_score = num_no_ans\n","  best_score = cur_score\n","  best_thresh = 0.0\n","  qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n","  for i, qid in enumerate(qid_list):\n","    if qid not in scores: continue\n","    if qid_to_has_ans[qid]:\n","      diff = scores[qid]\n","    else:\n","      if preds[qid]:\n","        diff = -1\n","      else:\n","        diff = 0\n","    cur_score += diff\n","    if cur_score > best_score:\n","      best_score = cur_score\n","      best_thresh = na_probs[qid]\n","  return 100.0 * best_score / len(scores), best_thresh\n","\n","def find_best_thresh_v2(preds, scores, na_probs, qid_to_has_ans):\n","  num_no_ans = sum(1 for k in qid_to_has_ans if not qid_to_has_ans[k])\n","  cur_score = num_no_ans\n","  best_score = cur_score\n","  best_thresh = 0.0\n","  qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n","  for i, qid in enumerate(qid_list):\n","    if qid not in scores: continue\n","    if qid_to_has_ans[qid]:\n","      diff = scores[qid]\n","    else:\n","      if preds[qid]:\n","        diff = -1\n","      else:\n","        diff = 0\n","    cur_score += diff\n","    if cur_score > best_score:\n","      best_score = cur_score\n","      best_thresh = na_probs[qid]\n","\n","  has_ans_score, has_ans_cnt = 0, 0\n","  for qid in qid_list:\n","    if not qid_to_has_ans[qid]: continue\n","    has_ans_cnt += 1\n","\n","    if qid not in scores: continue\n","    has_ans_score += scores[qid]\n","\n","  return 100.0 * best_score / len(scores), best_thresh, 1.0 * has_ans_score / has_ans_cnt\n","\n","def find_all_best_thresh(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans):\n","  best_exact, exact_thresh = find_best_thresh(preds, exact_raw, na_probs, qid_to_has_ans)\n","  best_f1, f1_thresh = find_best_thresh(preds, f1_raw, na_probs, qid_to_has_ans)\n","  main_eval['best_exact'] = best_exact\n","  main_eval['best_exact_thresh'] = exact_thresh\n","  main_eval['best_f1'] = best_f1\n","  main_eval['best_f1_thresh'] = f1_thresh\n","\n","def find_all_best_thresh_v2(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans):\n","  best_exact, exact_thresh, has_ans_exact = find_best_thresh_v2(preds, exact_raw, na_probs, qid_to_has_ans)\n","  best_f1, f1_thresh, has_ans_f1 = find_best_thresh_v2(preds, f1_raw, na_probs, qid_to_has_ans)\n","  main_eval['best_exact'] = best_exact\n","  main_eval['best_exact_thresh'] = exact_thresh\n","  main_eval['best_f1'] = best_f1\n","  main_eval['best_f1_thresh'] = f1_thresh\n","  main_eval['has_ans_exact'] = has_ans_exact\n","  main_eval['has_ans_f1'] = has_ans_f1\n","\n","def main(OPTS):\n","  with open(OPTS.data_file) as f:\n","    dataset_json = json.load(f)\n","    dataset = dataset_json['data']\n","  with open(OPTS.pred_file) as f:\n","    preds = json.load(f)\n","  if OPTS.na_prob_file:\n","    with open(OPTS.na_prob_file) as f:\n","      na_probs = json.load(f)\n","  else:\n","    na_probs = {k: 0.0 for k in preds}\n","  qid_to_has_ans = make_qid_to_has_ans(dataset)  # maps qid to True/False\n","  has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n","  no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n","  exact_raw, f1_raw = get_raw_scores(dataset, preds)\n","  exact_thresh = apply_no_ans_threshold(exact_raw, na_probs, qid_to_has_ans,\n","                                        OPTS.na_prob_thresh)\n","  f1_thresh = apply_no_ans_threshold(f1_raw, na_probs, qid_to_has_ans,\n","                                     OPTS.na_prob_thresh)\n","  out_eval = make_eval_dict(exact_thresh, f1_thresh)\n","  if has_ans_qids:\n","    has_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=has_ans_qids)\n","    merge_eval(out_eval, has_ans_eval, 'HasAns')\n","  if no_ans_qids:\n","    no_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=no_ans_qids)\n","    merge_eval(out_eval, no_ans_eval, 'NoAns')\n","  if OPTS.na_prob_file:\n","    find_all_best_thresh(out_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans)\n","  if OPTS.na_prob_file and OPTS.out_image_dir:\n","    run_precision_recall_analysis(out_eval, exact_raw, f1_raw, na_probs, \n","                                  qid_to_has_ans, OPTS.out_image_dir)\n","    histogram_na_prob(na_probs, has_ans_qids, OPTS.out_image_dir, 'hasAns')\n","    histogram_na_prob(na_probs, no_ans_qids, OPTS.out_image_dir, 'noAns')\n","  if OPTS.out_file:\n","    with open(OPTS.out_file, 'w') as f:\n","      json.dump(out_eval, f)\n","  else:\n","    print(json.dumps(out_eval, indent=2))\n","  return out_eval\n","\n","# if __name__ == '__main__':\n","#   OPTS = parse_args()\n","#   if OPTS.out_image_dir:\n","#     import matplotlib\n","#     matplotlib.use('Agg')\n","#     import matplotlib.pyplot as plt \n","#   main(OPTS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20Q5DNanIqVP"},"source":["# coding=utf-8\n","# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n","# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\" Load SQuAD dataset. \"\"\"\n","\n","from __future__ import absolute_import, division, print_function\n","\n","import json\n","import logging\n","import math\n","import collections\n","from io import open\n","\n","from pytorch_transformers.tokenization_bert import BasicTokenizer, whitespace_tokenize\n","\n","# Required by XLNet evaluation method to compute optimal threshold (see write_predictions_extended() method)\n","# from utils_squad_evaluate import find_all_best_thresh_v2, make_qid_to_has_ans, get_raw_scores\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","class SquadExample(object):\n","    \"\"\"\n","    A single training/test example for the Squad dataset.\n","    For examples without an answer, the start and end position are -1.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 qas_id,\n","                 question_text,\n","                 doc_tokens,\n","                 orig_answer_text=None,\n","                 start_position=None,\n","                 end_position=None,\n","                 is_impossible=None):\n","        self.qas_id = qas_id\n","        self.question_text = question_text\n","        self.doc_tokens = doc_tokens\n","        self.orig_answer_text = orig_answer_text\n","        self.start_position = start_position\n","        self.end_position = end_position\n","        self.is_impossible = is_impossible\n","\n","    def __str__(self):\n","        return self.__repr__()\n","\n","    def __repr__(self):\n","        s = \"\"\n","        s += \"qas_id: %s\" % (self.qas_id)\n","        s += \", question_text: %s\" % (\n","            self.question_text)\n","        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n","        if self.start_position:\n","            s += \", start_position: %d\" % (self.start_position)\n","        if self.end_position:\n","            s += \", end_position: %d\" % (self.end_position)\n","        if self.is_impossible:\n","            s += \", is_impossible: %r\" % (self.is_impossible)\n","        return s\n","\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self,\n","                 unique_id,\n","                 example_index,\n","                 doc_span_index,\n","                 tokens,\n","                 token_to_orig_map,\n","                 token_is_max_context,\n","                 input_ids,\n","                 input_mask,\n","                 segment_ids,\n","                 cls_index,\n","                 p_mask,\n","                 paragraph_len,\n","                 start_position=None,\n","                 end_position=None,\n","                 is_impossible=None):\n","        self.unique_id = unique_id\n","        self.example_index = example_index\n","        self.doc_span_index = doc_span_index\n","        self.tokens = tokens\n","        self.token_to_orig_map = token_to_orig_map\n","        self.token_is_max_context = token_is_max_context\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.cls_index = cls_index\n","        self.p_mask = p_mask\n","        self.paragraph_len = paragraph_len\n","        self.start_position = start_position\n","        self.end_position = end_position\n","        self.is_impossible = is_impossible\n","\n","\n","def read_squad_examples(input_file, is_training, version_2_with_negative):\n","    \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n","    with open(input_file, \"r\", encoding='utf-8') as reader:\n","        input_data = json.load(reader)[\"data\"]\n","\n","    def is_whitespace(c):\n","        if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n","            return True\n","        return False\n","\n","    examples = []\n","    for entry in input_data:\n","        for paragraph in entry[\"paragraphs\"]:\n","            paragraph_text = paragraph[\"context\"]\n","            doc_tokens = []\n","            char_to_word_offset = []\n","            prev_is_whitespace = True\n","            for c in paragraph_text:\n","                if is_whitespace(c):\n","                    prev_is_whitespace = True\n","                else:\n","                    if prev_is_whitespace:\n","                        doc_tokens.append(c)\n","                    else:\n","                        doc_tokens[-1] += c\n","                    prev_is_whitespace = False\n","                char_to_word_offset.append(len(doc_tokens) - 1)\n","\n","            for qa in paragraph[\"qas\"]:\n","                qas_id = qa[\"id\"]\n","                question_text = qa[\"question\"]\n","                start_position = None\n","                end_position = None\n","                orig_answer_text = None\n","                is_impossible = False\n","                if is_training:\n","                    if version_2_with_negative:\n","                        is_impossible = qa[\"is_impossible\"]\n","                    if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n","                        raise ValueError(\n","                            \"For training, each question should have exactly 1 answer.\")\n","                    if not is_impossible:\n","                        answer = qa[\"answers\"][0]\n","                        orig_answer_text = answer[\"text\"]\n","                        answer_offset = answer[\"answer_start\"]\n","                        answer_length = len(orig_answer_text)\n","                        start_position = char_to_word_offset[answer_offset]\n","                        end_position = char_to_word_offset[answer_offset + answer_length - 1]\n","                        # Only add answers where the text can be exactly recovered from the\n","                        # document. If this CAN'T happen it's likely due to weird Unicode\n","                        # stuff so we will just skip the example.\n","                        #\n","                        # Note that this means for training mode, every example is NOT\n","                        # guaranteed to be preserved.\n","                        actual_text = \" \".join(doc_tokens[start_position:(end_position + 1)])\n","                        cleaned_answer_text = \" \".join(\n","                            whitespace_tokenize(orig_answer_text))\n","                        if actual_text.find(cleaned_answer_text) == -1:\n","                            logger.warning(\"Could not find answer: '%s' vs. '%s'\",\n","                                           actual_text, cleaned_answer_text)\n","                            continue\n","                    else:\n","                        start_position = -1\n","                        end_position = -1\n","                        orig_answer_text = \"\"\n","\n","                example = SquadExample(\n","                    qas_id=qas_id,\n","                    question_text=question_text,\n","                    doc_tokens=doc_tokens,\n","                    orig_answer_text=orig_answer_text,\n","                    start_position=start_position,\n","                    end_position=end_position,\n","                    is_impossible=is_impossible)\n","                examples.append(example)\n","    return examples\n","\n","\n","def convert_examples_to_features(examples, tokenizer, max_seq_length,\n","                                 doc_stride, max_query_length, is_training,\n","                                 cls_token_at_end=False,\n","                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n","                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\n","                                 cls_token_segment_id=0, pad_token_segment_id=0,\n","                                 mask_padding_with_zero=True):\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n","\n","    unique_id = 1000000000\n","    # cnt_pos, cnt_neg = 0, 0\n","    # max_N, max_M = 1024, 1024\n","    # f = np.zeros((max_N, max_M), dtype=np.float32)\n","\n","    features = []\n","    for (example_index, example) in enumerate(examples):\n","\n","        # if example_index % 100 == 0:\n","        #     logger.info('Converting %s/%s pos %s neg %s', example_index, len(examples), cnt_pos, cnt_neg)\n","\n","        query_tokens = tokenizer.tokenize(example.question_text)\n","\n","        if len(query_tokens) > max_query_length:\n","            query_tokens = query_tokens[0:max_query_length]\n","\n","        tok_to_orig_index = []\n","        orig_to_tok_index = []\n","        all_doc_tokens = []\n","        for (i, token) in enumerate(example.doc_tokens):\n","            orig_to_tok_index.append(len(all_doc_tokens))\n","            sub_tokens = tokenizer.tokenize(token)\n","            for sub_token in sub_tokens:\n","                tok_to_orig_index.append(i)\n","                all_doc_tokens.append(sub_token)\n","\n","        tok_start_position = None\n","        tok_end_position = None\n","        if is_training and example.is_impossible:\n","            tok_start_position = -1\n","            tok_end_position = -1\n","        if is_training and not example.is_impossible:\n","            tok_start_position = orig_to_tok_index[example.start_position]\n","            if example.end_position < len(example.doc_tokens) - 1:\n","                tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n","            else:\n","                tok_end_position = len(all_doc_tokens) - 1\n","            (tok_start_position, tok_end_position) = _improve_answer_span(\n","                all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n","                example.orig_answer_text)\n","\n","        # The -3 accounts for [CLS], [SEP] and [SEP]\n","        max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n","\n","        # We can have documents that are longer than the maximum sequence length.\n","        # To deal with this we do a sliding window approach, where we take chunks\n","        # of the up to our max length with a stride of `doc_stride`.\n","        _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n","            \"DocSpan\", [\"start\", \"length\"])\n","        doc_spans = []\n","        start_offset = 0\n","        while start_offset < len(all_doc_tokens):\n","            length = len(all_doc_tokens) - start_offset\n","            if length > max_tokens_for_doc:\n","                length = max_tokens_for_doc\n","            doc_spans.append(_DocSpan(start=start_offset, length=length))\n","            if start_offset + length == len(all_doc_tokens):\n","                break\n","            start_offset += min(length, doc_stride)\n","\n","        for (doc_span_index, doc_span) in enumerate(doc_spans):\n","            tokens = []\n","            token_to_orig_map = {}\n","            token_is_max_context = {}\n","            segment_ids = []\n","\n","            # p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)\n","            # Original TF implem also keep the classification token (set to 0) (not sure why...)\n","            p_mask = []\n","\n","            # CLS token at the beginning\n","            if not cls_token_at_end:\n","                tokens.append(cls_token)\n","                segment_ids.append(cls_token_segment_id)\n","                p_mask.append(0)\n","                cls_index = 0\n","\n","            # Query\n","            for token in query_tokens:\n","                tokens.append(token)\n","                segment_ids.append(sequence_a_segment_id)\n","                p_mask.append(1)\n","\n","            # SEP token\n","            tokens.append(sep_token)\n","            segment_ids.append(sequence_a_segment_id)\n","            p_mask.append(1)\n","\n","            # Paragraph\n","            for i in range(doc_span.length):\n","                split_token_index = doc_span.start + i\n","                token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n","\n","                is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n","                                                       split_token_index)\n","                token_is_max_context[len(tokens)] = is_max_context\n","                tokens.append(all_doc_tokens[split_token_index])\n","                segment_ids.append(sequence_b_segment_id)\n","                p_mask.append(0)\n","            paragraph_len = doc_span.length\n","\n","            # SEP token\n","            tokens.append(sep_token)\n","            segment_ids.append(sequence_b_segment_id)\n","            p_mask.append(1)\n","\n","            # CLS token at the end\n","            if cls_token_at_end:\n","                tokens.append(cls_token)\n","                segment_ids.append(cls_token_segment_id)\n","                p_mask.append(0)\n","                cls_index = len(tokens) - 1  # Index of classification token\n","\n","            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","            # tokens are attended to.\n","            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n","\n","            # Zero-pad up to the sequence length.\n","            while len(input_ids) < max_seq_length:\n","                input_ids.append(pad_token)\n","                input_mask.append(0 if mask_padding_with_zero else 1)\n","                segment_ids.append(pad_token_segment_id)\n","                p_mask.append(1)\n","\n","            assert len(input_ids) == max_seq_length\n","            assert len(input_mask) == max_seq_length\n","            assert len(segment_ids) == max_seq_length\n","\n","            span_is_impossible = example.is_impossible\n","            start_position = None\n","            end_position = None\n","            if is_training and not span_is_impossible:\n","                # For training, if our document chunk does not contain an annotation\n","                # we throw it out, since there is nothing to predict.\n","                doc_start = doc_span.start\n","                doc_end = doc_span.start + doc_span.length - 1\n","                out_of_span = False\n","                if not (tok_start_position >= doc_start and\n","                        tok_end_position <= doc_end):\n","                    out_of_span = True\n","                if out_of_span:\n","                    start_position = 0\n","                    end_position = 0\n","                    span_is_impossible = True\n","                else:\n","                    doc_offset = len(query_tokens) + 2\n","                    start_position = tok_start_position - doc_start + doc_offset\n","                    end_position = tok_end_position - doc_start + doc_offset\n","\n","            if is_training and span_is_impossible:\n","                start_position = cls_index\n","                end_position = cls_index\n","\n","            if example_index < 20:\n","                logger.info(\"*** Example ***\")\n","                logger.info(\"unique_id: %s\" % (unique_id))\n","                logger.info(\"example_index: %s\" % (example_index))\n","                logger.info(\"doc_span_index: %s\" % (doc_span_index))\n","                logger.info(\"tokens: %s\" % \" \".join(tokens))\n","                logger.info(\"token_to_orig_map: %s\" % \" \".join([\n","                    \"%d:%d\" % (x, y) for (x, y) in token_to_orig_map.items()]))\n","                logger.info(\"token_is_max_context: %s\" % \" \".join([\n","                    \"%d:%s\" % (x, y) for (x, y) in token_is_max_context.items()\n","                ]))\n","                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n","                logger.info(\n","                    \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n","                logger.info(\n","                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n","                if is_training and span_is_impossible:\n","                    logger.info(\"impossible example\")\n","                if is_training and not span_is_impossible:\n","                    answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n","                    logger.info(\"start_position: %d\" % (start_position))\n","                    logger.info(\"end_position: %d\" % (end_position))\n","                    logger.info(\n","                        \"answer: %s\" % (answer_text))\n","\n","            features.append(\n","                InputFeatures(\n","                    unique_id=unique_id,\n","                    example_index=example_index,\n","                    doc_span_index=doc_span_index,\n","                    tokens=tokens,\n","                    token_to_orig_map=token_to_orig_map,\n","                    token_is_max_context=token_is_max_context,\n","                    input_ids=input_ids,\n","                    input_mask=input_mask,\n","                    segment_ids=segment_ids,\n","                    cls_index=cls_index,\n","                    p_mask=p_mask,\n","                    paragraph_len=paragraph_len,\n","                    start_position=start_position,\n","                    end_position=end_position,\n","                    is_impossible=span_is_impossible))\n","            unique_id += 1\n","\n","    return features\n","\n","\n","def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n","                         orig_answer_text):\n","    \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n","\n","    # The SQuAD annotations are character based. We first project them to\n","    # whitespace-tokenized words. But then after WordPiece tokenization, we can\n","    # often find a \"better match\". For example:\n","    #\n","    #   Question: What year was John Smith born?\n","    #   Context: The leader was John Smith (1895-1943).\n","    #   Answer: 1895\n","    #\n","    # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n","    # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n","    # the exact answer, 1895.\n","    #\n","    # However, this is not always possible. Consider the following:\n","    #\n","    #   Question: What country is the top exporter of electornics?\n","    #   Context: The Japanese electronics industry is the lagest in the world.\n","    #   Answer: Japan\n","    #\n","    # In this case, the annotator chose \"Japan\" as a character sub-span of\n","    # the word \"Japanese\". Since our WordPiece tokenizer does not split\n","    # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n","    # in SQuAD, but does happen.\n","    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n","\n","    for new_start in range(input_start, input_end + 1):\n","        for new_end in range(input_end, new_start - 1, -1):\n","            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n","            if text_span == tok_answer_text:\n","                return (new_start, new_end)\n","\n","    return (input_start, input_end)\n","\n","\n","def _check_is_max_context(doc_spans, cur_span_index, position):\n","    \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n","\n","    # Because of the sliding window approach taken to scoring documents, a single\n","    # token can appear in multiple documents. E.g.\n","    #  Doc: the man went to the store and bought a gallon of milk\n","    #  Span A: the man went to the\n","    #  Span B: to the store and bought\n","    #  Span C: and bought a gallon of\n","    #  ...\n","    #\n","    # Now the word 'bought' will have two scores from spans B and C. We only\n","    # want to consider the score with \"maximum context\", which we define as\n","    # the *minimum* of its left and right context (the *sum* of left and\n","    # right context will always be the same, of course).\n","    #\n","    # In the example the maximum context for 'bought' would be span C since\n","    # it has 1 left context and 3 right context, while span B has 4 left context\n","    # and 0 right context.\n","    best_score = None\n","    best_span_index = None\n","    for (span_index, doc_span) in enumerate(doc_spans):\n","        end = doc_span.start + doc_span.length - 1\n","        if position < doc_span.start:\n","            continue\n","        if position > end:\n","            continue\n","        num_left_context = position - doc_span.start\n","        num_right_context = end - position\n","        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n","        if best_score is None or score > best_score:\n","            best_score = score\n","            best_span_index = span_index\n","\n","    return cur_span_index == best_span_index\n","\n","\n","RawResult = collections.namedtuple(\"RawResult\",\n","                                   [\"unique_id\", \"start_logits\", \"end_logits\"])\n","\n","def write_predictions(all_examples, all_features, all_results, n_best_size,\n","                      max_answer_length, do_lower_case, output_prediction_file,\n","                      output_nbest_file, output_null_log_odds_file, verbose_logging,\n","                      version_2_with_negative, null_score_diff_threshold):\n","    \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n","    logger.info(\"Writing predictions to: %s\" % (output_prediction_file))\n","    logger.info(\"Writing nbest to: %s\" % (output_nbest_file))\n","\n","    example_index_to_features = collections.defaultdict(list)\n","    for feature in all_features:\n","        example_index_to_features[feature.example_index].append(feature)\n","\n","    unique_id_to_result = {}\n","    for result in all_results:\n","        unique_id_to_result[result.unique_id] = result\n","\n","    _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","        \"PrelimPrediction\",\n","        [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n","\n","    all_predictions = collections.OrderedDict()\n","    all_nbest_json = collections.OrderedDict()\n","    scores_diff_json = collections.OrderedDict()\n","\n","    for (example_index, example) in enumerate(all_examples):\n","        features = example_index_to_features[example_index]\n","\n","        prelim_predictions = []\n","        # keep track of the minimum score of null start+end of position 0\n","        score_null = 1000000  # large and positive\n","        min_null_feature_index = 0  # the paragraph slice with min null score\n","        null_start_logit = 0  # the start logit at the slice with min null score\n","        null_end_logit = 0  # the end logit at the slice with min null score\n","        for (feature_index, feature) in enumerate(features):\n","            result = unique_id_to_result[feature.unique_id]\n","            start_indexes = _get_best_indexes(result.start_logits, n_best_size)\n","            end_indexes = _get_best_indexes(result.end_logits, n_best_size)\n","            # if we could have irrelevant answers, get the min score of irrelevant\n","            if version_2_with_negative:\n","                feature_null_score = result.start_logits[0] + result.end_logits[0]\n","                if feature_null_score < score_null:\n","                    score_null = feature_null_score\n","                    min_null_feature_index = feature_index\n","                    null_start_logit = result.start_logits[0]\n","                    null_end_logit = result.end_logits[0]\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # We could hypothetically create invalid predictions, e.g., predict\n","                    # that the start of the span is in the question. We throw out all\n","                    # invalid predictions.\n","                    if start_index >= len(feature.tokens):\n","                        continue\n","                    if end_index >= len(feature.tokens):\n","                        continue\n","                    if start_index not in feature.token_to_orig_map:\n","                        continue\n","                    if end_index not in feature.token_to_orig_map:\n","                        continue\n","                    if not feature.token_is_max_context.get(start_index, False):\n","                        continue\n","                    if end_index < start_index:\n","                        continue\n","                    length = end_index - start_index + 1\n","                    if length > max_answer_length:\n","                        continue\n","                    prelim_predictions.append(\n","                        _PrelimPrediction(\n","                            feature_index=feature_index,\n","                            start_index=start_index,\n","                            end_index=end_index,\n","                            start_logit=result.start_logits[start_index],\n","                            end_logit=result.end_logits[end_index]))\n","        if version_2_with_negative:\n","            prelim_predictions.append(\n","                _PrelimPrediction(\n","                    feature_index=min_null_feature_index,\n","                    start_index=0,\n","                    end_index=0,\n","                    start_logit=null_start_logit,\n","                    end_logit=null_end_logit))\n","        prelim_predictions = sorted(\n","            prelim_predictions,\n","            key=lambda x: (x.start_logit + x.end_logit),\n","            reverse=True)\n","\n","        _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","            \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n","\n","        seen_predictions = {}\n","        nbest = []\n","        for pred in prelim_predictions:\n","            if len(nbest) >= n_best_size:\n","                break\n","            feature = features[pred.feature_index]\n","            if pred.start_index > 0:  # this is a non-null prediction\n","                tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n","                orig_doc_start = feature.token_to_orig_map[pred.start_index]\n","                orig_doc_end = feature.token_to_orig_map[pred.end_index]\n","                orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n","                tok_text = \" \".join(tok_tokens)\n","\n","                # De-tokenize WordPieces that have been split off.\n","                tok_text = tok_text.replace(\" ##\", \"\")\n","                tok_text = tok_text.replace(\"##\", \"\")\n","\n","                # Clean whitespace\n","                tok_text = tok_text.strip()\n","                tok_text = \" \".join(tok_text.split())\n","                orig_text = \" \".join(orig_tokens)\n","\n","                final_text = get_final_text(tok_text, orig_text, do_lower_case, verbose_logging)\n","                if final_text in seen_predictions:\n","                    continue\n","\n","                seen_predictions[final_text] = True\n","            else:\n","                final_text = \"\"\n","                seen_predictions[final_text] = True\n","\n","            nbest.append(\n","                _NbestPrediction(\n","                    text=final_text,\n","                    start_logit=pred.start_logit,\n","                    end_logit=pred.end_logit))\n","        # if we didn't include the empty option in the n-best, include it\n","        if version_2_with_negative:\n","            if \"\" not in seen_predictions:\n","                nbest.append(\n","                    _NbestPrediction(\n","                        text=\"\",\n","                        start_logit=null_start_logit,\n","                        end_logit=null_end_logit))\n","                \n","            # In very rare edge cases we could only have single null prediction.\n","            # So we just create a nonce prediction in this case to avoid failure.\n","            if len(nbest)==1:\n","                nbest.insert(0,\n","                    _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n","\n","        # In very rare edge cases we could have no valid predictions. So we\n","        # just create a nonce prediction in this case to avoid failure.\n","        if not nbest:\n","            nbest.append(\n","                _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n","\n","        assert len(nbest) >= 1\n","\n","        total_scores = []\n","        best_non_null_entry = None\n","        for entry in nbest:\n","            total_scores.append(entry.start_logit + entry.end_logit)\n","            if not best_non_null_entry:\n","                if entry.text:\n","                    best_non_null_entry = entry\n","\n","        probs = _compute_softmax(total_scores)\n","\n","        nbest_json = []\n","        for (i, entry) in enumerate(nbest):\n","            output = collections.OrderedDict()\n","            output[\"text\"] = entry.text\n","            output[\"probability\"] = probs[i]\n","            output[\"start_logit\"] = entry.start_logit\n","            output[\"end_logit\"] = entry.end_logit\n","            nbest_json.append(output)\n","\n","        assert len(nbest_json) >= 1\n","\n","        if not version_2_with_negative:\n","            all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n","        else:\n","            # predict \"\" iff the null score - the score of best non-null > threshold\n","            score_diff = score_null - best_non_null_entry.start_logit - (\n","                best_non_null_entry.end_logit)\n","            scores_diff_json[example.qas_id] = score_diff\n","            if score_diff > null_score_diff_threshold:\n","                all_predictions[example.qas_id] = \"\"\n","            else:\n","                all_predictions[example.qas_id] = best_non_null_entry.text\n","        all_nbest_json[example.qas_id] = nbest_json\n","\n","    with open(output_prediction_file, \"w\") as writer:\n","        writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n","\n","    with open(output_nbest_file, \"w\") as writer:\n","        writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n","\n","    if version_2_with_negative:\n","        with open(output_null_log_odds_file, \"w\") as writer:\n","            writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")\n","\n","    return all_predictions\n","\n","\n","# For XLNet (and XLM which uses the same head)\n","RawResultExtended = collections.namedtuple(\"RawResultExtended\",\n","    [\"unique_id\", \"start_top_log_probs\", \"start_top_index\",\n","     \"end_top_log_probs\", \"end_top_index\", \"cls_logits\"])\n","\n","\n","def write_predictions_extended(all_examples, all_features, all_results, n_best_size,\n","                                max_answer_length, output_prediction_file,\n","                                output_nbest_file,\n","                                output_null_log_odds_file, orig_data_file,\n","                                start_n_top, end_n_top, version_2_with_negative,\n","                                tokenizer, verbose_logging):\n","    \"\"\" XLNet write prediction logic (more complex than Bert's).\n","        Write final predictions to the json file and log-odds of null if needed.\n","        Requires utils_squad_evaluate.py\n","    \"\"\"\n","    _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","        \"PrelimPrediction\",\n","        [\"feature_index\", \"start_index\", \"end_index\",\n","        \"start_log_prob\", \"end_log_prob\"])\n","\n","    _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","        \"NbestPrediction\", [\"text\", \"start_log_prob\", \"end_log_prob\"])\n","\n","    logger.info(\"Writing predictions to: %s\", output_prediction_file)\n","    # logger.info(\"Writing nbest to: %s\" % (output_nbest_file))\n","\n","    example_index_to_features = collections.defaultdict(list)\n","    for feature in all_features:\n","        example_index_to_features[feature.example_index].append(feature)\n","\n","    unique_id_to_result = {}\n","    for result in all_results:\n","        unique_id_to_result[result.unique_id] = result\n","\n","    all_predictions = collections.OrderedDict()\n","    all_nbest_json = collections.OrderedDict()\n","    scores_diff_json = collections.OrderedDict()\n","\n","    for (example_index, example) in enumerate(all_examples):\n","        features = example_index_to_features[example_index]\n","\n","        prelim_predictions = []\n","        # keep track of the minimum score of null start+end of position 0\n","        score_null = 1000000  # large and positive\n","\n","        for (feature_index, feature) in enumerate(features):\n","            result = unique_id_to_result[feature.unique_id]\n","\n","            cur_null_score = result.cls_logits\n","\n","            # if we could have irrelevant answers, get the min score of irrelevant\n","            score_null = min(score_null, cur_null_score)\n","\n","            for i in range(start_n_top):\n","                for j in range(end_n_top):\n","                    start_log_prob = result.start_top_log_probs[i]\n","                    start_index = result.start_top_index[i]\n","\n","                    j_index = i * end_n_top + j\n","\n","                    end_log_prob = result.end_top_log_probs[j_index]\n","                    end_index = result.end_top_index[j_index]\n","\n","                    # We could hypothetically create invalid predictions, e.g., predict\n","                    # that the start of the span is in the question. We throw out all\n","                    # invalid predictions.\n","                    if start_index >= feature.paragraph_len - 1:\n","                        continue\n","                    if end_index >= feature.paragraph_len - 1:\n","                        continue\n","\n","                    if not feature.token_is_max_context.get(start_index, False):\n","                        continue\n","                    if end_index < start_index:\n","                        continue\n","                    length = end_index - start_index + 1\n","                    if length > max_answer_length:\n","                        continue\n","\n","                    prelim_predictions.append(\n","                        _PrelimPrediction(\n","                            feature_index=feature_index,\n","                            start_index=start_index,\n","                            end_index=end_index,\n","                            start_log_prob=start_log_prob,\n","                            end_log_prob=end_log_prob))\n","\n","        prelim_predictions = sorted(\n","            prelim_predictions,\n","            key=lambda x: (x.start_log_prob + x.end_log_prob),\n","            reverse=True)\n","\n","        seen_predictions = {}\n","        nbest = []\n","        for pred in prelim_predictions:\n","            if len(nbest) >= n_best_size:\n","                break\n","            feature = features[pred.feature_index]\n","\n","            # XLNet un-tokenizer\n","            # Let's keep it simple for now and see if we need all this later.\n","            # \n","            # tok_start_to_orig_index = feature.tok_start_to_orig_index\n","            # tok_end_to_orig_index = feature.tok_end_to_orig_index\n","            # start_orig_pos = tok_start_to_orig_index[pred.start_index]\n","            # end_orig_pos = tok_end_to_orig_index[pred.end_index]\n","            # paragraph_text = example.paragraph_text\n","            # final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()\n","\n","            # Previously used Bert untokenizer\n","            tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n","            orig_doc_start = feature.token_to_orig_map[pred.start_index]\n","            orig_doc_end = feature.token_to_orig_map[pred.end_index]\n","            orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n","            tok_text = tokenizer.convert_tokens_to_string(tok_tokens)\n","\n","            # Clean whitespace\n","            tok_text = tok_text.strip()\n","            tok_text = \" \".join(tok_text.split())\n","            orig_text = \" \".join(orig_tokens)\n","\n","            final_text = get_final_text(tok_text, orig_text, tokenizer.do_lower_case,\n","                                        verbose_logging)\n","\n","            if final_text in seen_predictions:\n","                continue\n","\n","            seen_predictions[final_text] = True\n","\n","            nbest.append(\n","                _NbestPrediction(\n","                    text=final_text,\n","                    start_log_prob=pred.start_log_prob,\n","                    end_log_prob=pred.end_log_prob))\n","\n","        # In very rare edge cases we could have no valid predictions. So we\n","        # just create a nonce prediction in this case to avoid failure.\n","        if not nbest:\n","            nbest.append(\n","                _NbestPrediction(text=\"\", start_log_prob=-1e6,\n","                end_log_prob=-1e6))\n","\n","        total_scores = []\n","        best_non_null_entry = None\n","        for entry in nbest:\n","            total_scores.append(entry.start_log_prob + entry.end_log_prob)\n","            if not best_non_null_entry:\n","                best_non_null_entry = entry\n","\n","        probs = _compute_softmax(total_scores)\n","\n","        nbest_json = []\n","        for (i, entry) in enumerate(nbest):\n","            output = collections.OrderedDict()\n","            output[\"text\"] = entry.text\n","            output[\"probability\"] = probs[i]\n","            output[\"start_log_prob\"] = entry.start_log_prob\n","            output[\"end_log_prob\"] = entry.end_log_prob\n","            nbest_json.append(output)\n","\n","        assert len(nbest_json) >= 1\n","        assert best_non_null_entry is not None\n","\n","        score_diff = score_null\n","        scores_diff_json[example.qas_id] = score_diff\n","        # note(zhiliny): always predict best_non_null_entry\n","        # and the evaluation script will search for the best threshold\n","        all_predictions[example.qas_id] = best_non_null_entry.text\n","\n","        all_nbest_json[example.qas_id] = nbest_json\n","\n","    with open(output_prediction_file, \"w\") as writer:\n","        writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n","\n","    with open(output_nbest_file, \"w\") as writer:\n","        writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n","\n","    if version_2_with_negative:\n","        with open(output_null_log_odds_file, \"w\") as writer:\n","            writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")\n","\n","    with open(orig_data_file, \"r\", encoding='utf-8') as reader:\n","        orig_data = json.load(reader)[\"data\"]\n","\n","    qid_to_has_ans = make_qid_to_has_ans(orig_data)\n","    has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n","    no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n","    exact_raw, f1_raw = get_raw_scores(orig_data, all_predictions)\n","    out_eval = {}\n","\n","    find_all_best_thresh_v2(out_eval, all_predictions, exact_raw, f1_raw, scores_diff_json, qid_to_has_ans)\n","\n","    return out_eval\n","\n","\n","def get_final_text(pred_text, orig_text, do_lower_case, verbose_logging=False):\n","    \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n","\n","    # When we created the data, we kept track of the alignment between original\n","    # (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n","    # now `orig_text` contains the span of our original text corresponding to the\n","    # span that we predicted.\n","    #\n","    # However, `orig_text` may contain extra characters that we don't want in\n","    # our prediction.\n","    #\n","    # For example, let's say:\n","    #   pred_text = steve smith\n","    #   orig_text = Steve Smith's\n","    #\n","    # We don't want to return `orig_text` because it contains the extra \"'s\".\n","    #\n","    # We don't want to return `pred_text` because it's already been normalized\n","    # (the SQuAD eval script also does punctuation stripping/lower casing but\n","    # our tokenizer does additional normalization like stripping accent\n","    # characters).\n","    #\n","    # What we really want to return is \"Steve Smith\".\n","    #\n","    # Therefore, we have to apply a semi-complicated alignment heuristic between\n","    # `pred_text` and `orig_text` to get a character-to-character alignment. This\n","    # can fail in certain cases in which case we just return `orig_text`.\n","\n","    def _strip_spaces(text):\n","        ns_chars = []\n","        ns_to_s_map = collections.OrderedDict()\n","        for (i, c) in enumerate(text):\n","            if c == \" \":\n","                continue\n","            ns_to_s_map[len(ns_chars)] = i\n","            ns_chars.append(c)\n","        ns_text = \"\".join(ns_chars)\n","        return (ns_text, ns_to_s_map)\n","\n","    # We first tokenize `orig_text`, strip whitespace from the result\n","    # and `pred_text`, and check if they are the same length. If they are\n","    # NOT the same length, the heuristic has failed. If they are the same\n","    # length, we assume the characters are one-to-one aligned.\n","    tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n","\n","    tok_text = \" \".join(tokenizer.tokenize(orig_text))\n","\n","    start_position = tok_text.find(pred_text)\n","    if start_position == -1:\n","        if verbose_logging:\n","            logger.info(\n","                \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n","        return orig_text\n","    end_position = start_position + len(pred_text) - 1\n","\n","    (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n","    (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n","\n","    if len(orig_ns_text) != len(tok_ns_text):\n","        if verbose_logging:\n","            logger.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n","                        orig_ns_text, tok_ns_text)\n","        return orig_text\n","\n","    # We then project the characters in `pred_text` back to `orig_text` using\n","    # the character-to-character alignment.\n","    tok_s_to_ns_map = {}\n","    for (i, tok_index) in tok_ns_to_s_map.items():\n","        tok_s_to_ns_map[tok_index] = i\n","\n","    orig_start_position = None\n","    if start_position in tok_s_to_ns_map:\n","        ns_start_position = tok_s_to_ns_map[start_position]\n","        if ns_start_position in orig_ns_to_s_map:\n","            orig_start_position = orig_ns_to_s_map[ns_start_position]\n","\n","    if orig_start_position is None:\n","        if verbose_logging:\n","            logger.info(\"Couldn't map start position\")\n","        return orig_text\n","\n","    orig_end_position = None\n","    if end_position in tok_s_to_ns_map:\n","        ns_end_position = tok_s_to_ns_map[end_position]\n","        if ns_end_position in orig_ns_to_s_map:\n","            orig_end_position = orig_ns_to_s_map[ns_end_position]\n","\n","    if orig_end_position is None:\n","        if verbose_logging:\n","            logger.info(\"Couldn't map end position\")\n","        return orig_text\n","\n","    output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n","    return output_text\n","\n","\n","def _get_best_indexes(logits, n_best_size):\n","    \"\"\"Get the n-best logits from a list.\"\"\"\n","    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n","\n","    best_indexes = []\n","    for i in range(len(index_and_score)):\n","        if i >= n_best_size:\n","            break\n","        best_indexes.append(index_and_score[i][0])\n","    return best_indexes\n","\n","\n","def _compute_softmax(scores):\n","    \"\"\"Compute softmax probability over raw logits.\"\"\"\n","    if not scores:\n","        return []\n","\n","    max_score = None\n","    for score in scores:\n","        if max_score is None or score > max_score:\n","            max_score = score\n","\n","    exp_scores = []\n","    total_sum = 0.0\n","    for score in scores:\n","        x = math.exp(score - max_score)\n","        exp_scores.append(x)\n","        total_sum += x\n","\n","    probs = []\n","    for score in exp_scores:\n","        probs.append(score / total_sum)\n","    return probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgX-Y0XcItFQ","executionInfo":{"status":"ok","timestamp":1616497220019,"user_tz":-330,"elapsed":5457,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"e0cbc376-0898-48c6-9d91-a1cb61a6f0f9"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"bbHaLUgCIvjy"},"source":["input_file = '/content/drive/MyDrive/Final-project/data/train-v2.0.json'\n","examples = read_squad_examples(input_file=input_file,\n","                                is_training=True,\n","                               version_2_with_negative=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6q3kfQmIzI6","executionInfo":{"status":"ok","timestamp":1616497234103,"user_tz":-330,"elapsed":657,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"8d4f9913-eb99-4ada-aa69-920b6f6ff486"},"source":["examples[:6]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[qas_id: 56be85543aeaaa14008c9063, question_text: When did Beyonce start becoming popular?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 39, end_position: 42,\n"," qas_id: 56be85543aeaaa14008c9065, question_text: What areas did Beyonce compete in when she was growing up?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 28, end_position: 30,\n"," qas_id: 56be85543aeaaa14008c9066, question_text: When did Beyonce leave Destiny's Child and become a solo singer?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 82, end_position: 82,\n"," qas_id: 56bf6b0f3aeaaa14008c9601, question_text: In what city and state did Beyonce  grow up? , doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 22, end_position: 23,\n"," qas_id: 56bf6b0f3aeaaa14008c9602, question_text: In which decade did Beyonce become famous?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 41, end_position: 42,\n"," qas_id: 56bf6b0f3aeaaa14008c9603, question_text: In what R&B group was she the lead singer?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 49, end_position: 50]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"ujW03R5CJwRm","executionInfo":{"status":"ok","timestamp":1616497235971,"user_tz":-330,"elapsed":988,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"ed84f4c2-19dc-4548-a07f-8d905a507279"},"source":["train_data = pd.DataFrame.from_records([vars(example) for example in examples])\n","train_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qas_id</th>\n","      <th>question_text</th>\n","      <th>doc_tokens</th>\n","      <th>orig_answer_text</th>\n","      <th>start_position</th>\n","      <th>end_position</th>\n","      <th>is_impossible</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>56be85543aeaaa14008c9063</td>\n","      <td>When did Beyonce start becoming popular?</td>\n","      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n","      <td>in the late 1990s</td>\n","      <td>39</td>\n","      <td>42</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>56be85543aeaaa14008c9065</td>\n","      <td>What areas did Beyonce compete in when she was...</td>\n","      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n","      <td>singing and dancing</td>\n","      <td>28</td>\n","      <td>30</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>56be85543aeaaa14008c9066</td>\n","      <td>When did Beyonce leave Destiny's Child and bec...</td>\n","      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n","      <td>2003</td>\n","      <td>82</td>\n","      <td>82</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56bf6b0f3aeaaa14008c9601</td>\n","      <td>In what city and state did Beyonce  grow up?</td>\n","      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n","      <td>Houston, Texas</td>\n","      <td>22</td>\n","      <td>23</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>56bf6b0f3aeaaa14008c9602</td>\n","      <td>In which decade did Beyonce become famous?</td>\n","      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n","      <td>late 1990s</td>\n","      <td>41</td>\n","      <td>42</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     qas_id  ... is_impossible\n","0  56be85543aeaaa14008c9063  ...         False\n","1  56be85543aeaaa14008c9065  ...         False\n","2  56be85543aeaaa14008c9066  ...         False\n","3  56bf6b0f3aeaaa14008c9601  ...         False\n","4  56bf6b0f3aeaaa14008c9602  ...         False\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"id":"08uLBlJ_J0Pv","executionInfo":{"status":"ok","timestamp":1616497237497,"user_tz":-330,"elapsed":694,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"ce6eed0d-aa8c-4e81-a4ad-ae06624d6ee6"},"source":["sample = train_data.sample(frac=1).head(1)\n","context = sample.doc_tokens.values\n","train_data[train_data.doc_tokens.values==context]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qas_id</th>\n","      <th>question_text</th>\n","      <th>doc_tokens</th>\n","      <th>orig_answer_text</th>\n","      <th>start_position</th>\n","      <th>end_position</th>\n","      <th>is_impossible</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>32935</th>\n","      <td>57098dc3ed30961900e842fc</td>\n","      <td>When can the roots of orthodox judaism be trac...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td>19th century</td>\n","      <td>14</td>\n","      <td>15</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>32936</th>\n","      <td>57098dc3ed30961900e842fd</td>\n","      <td>When did the German Jewry seek to reform Jewis...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td>early 19th century</td>\n","      <td>30</td>\n","      <td>32</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>32937</th>\n","      <td>57098dc3ed30961900e842fe</td>\n","      <td>what did orthodox jews seek to modernize?</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td>education</td>\n","      <td>48</td>\n","      <td>48</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>32938</th>\n","      <td>57098dc3ed30961900e842ff</td>\n","      <td>what did the German Jewry reject about the Torah?</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td>absolute divine authorship</td>\n","      <td>59</td>\n","      <td>61</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>32939</th>\n","      <td>5a578ab5770dc0001aeefc76</td>\n","      <td>Which century can the roots of Orthodox Judais...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td></td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>32940</th>\n","      <td>5a578ab5770dc0001aeefc77</td>\n","      <td>When did the Roman Jewry attempt to reform Jew...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td></td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>32941</th>\n","      <td>5a578ab5770dc0001aeefc78</td>\n","      <td>What did the German Jewry attempt in response ...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td></td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>32942</th>\n","      <td>5a578ab5770dc0001aeefc79</td>\n","      <td>Who made the claim that the Torah had divine a...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td></td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>32943</th>\n","      <td>5a578ab5770dc0001aeefc7a</td>\n","      <td>What part of the Torah was considered non-bind...</td>\n","      <td>[The, roots, of, Orthodox, Judaism, can, be, t...</td>\n","      <td></td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         qas_id  ... is_impossible\n","32935  57098dc3ed30961900e842fc  ...         False\n","32936  57098dc3ed30961900e842fd  ...         False\n","32937  57098dc3ed30961900e842fe  ...         False\n","32938  57098dc3ed30961900e842ff  ...         False\n","32939  5a578ab5770dc0001aeefc76  ...          True\n","32940  5a578ab5770dc0001aeefc77  ...          True\n","32941  5a578ab5770dc0001aeefc78  ...          True\n","32942  5a578ab5770dc0001aeefc79  ...          True\n","32943  5a578ab5770dc0001aeefc7a  ...          True\n","\n","[9 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"kf6U2nFXJ3c0"},"source":["import random\n","def print_squad_sample(train_data, line_length=14, separator_length=120):\n","  sample = train_data.sample(frac=1).head(1)\n","  context = sample.doc_tokens.values\n","  print('='*separator_length)\n","  print('CONTEXT: ')\n","  print('='*separator_length)\n","  lines = [' '.join(context[0][idx:idx+line_length]) for idx in range(0, len(context[0]), line_length)]\n","  for l in lines:\n","      print(l)\n","  print('='*separator_length)\n","  questions = train_data[train_data.doc_tokens.values==context]\n","  print('QUESTION:', ' '*(3*separator_length//4), 'ANSWER:')\n","  for idx, row in questions.iterrows():\n","    question = row.question_text\n","    answer = row.orig_answer_text\n","    print(question, ' '*(3*separator_length//4-len(question)+9), (answer if answer else 'No answer found'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJeXesKXJ7E0","executionInfo":{"status":"ok","timestamp":1616497243608,"user_tz":-330,"elapsed":731,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"e617920f-dfd6-4f87-af4f-7eb0b9d4c45e"},"source":["print_squad_sample(train_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["========================================================================================================================\n","CONTEXT: \n","========================================================================================================================\n","Between 1949 and the 1980s, telephone communications in Greece were a state monopoly by\n","the Hellenic Telecommunications Organization, better known by its acronym, OTE. Despite the liberalization of\n","telephone communications in the country in the 1980s, OTE still dominates the Greek market\n","in its field and has emerged as one of the largest telecommunications companies in\n","Southeast Europe. Since 2011, the company's major shareholder is Deutsche Telekom with a 40%\n","stake, while the Greek state continues to own 10% of the company's shares. OTE\n","owns several subsidiaries across the Balkans, including Cosmote, Greece's top mobile telecommunications provider, Cosmote\n","Romania and Albanian Mobile Communications.\n","========================================================================================================================\n","QUESTION:                                                                                            ANSWER:\n","Who ran the phones in Greece between 1949 and the 1980s?                                             state\n","What was the Hellenic Telecommunications Organization better known by the acronym of?                OTE\n","When did the liberalization of the telephone communications in Greece happen?                        1980s\n","What company has a 40% stake in OTE?                                                                 Deutsche Telekom\n","How many shares of OTE does the Greek state own?                                                     10%\n","Who removed the phones in Greece between 1949 and the 1980s?                                         No answer found\n","What was the Hellenic Telecommunications Organization not known as well by the acronym of?           No answer found\n","When did the liberalization of the telephone communications in Greece become impossible?             No answer found\n","What company lost a 40% stake in OTE?                                                                No answer found\n","How many shares of OTE does the Greek state sell?                                                    No answer found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"RXKcuoDGJ-jG","executionInfo":{"status":"ok","timestamp":1616497245724,"user_tz":-330,"elapsed":717,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"99be30d7-442f-498a-bc64-534634041298"},"source":["train_data['paragraph_len'] = train_data['doc_tokens'].apply(len)\n","train_data['question_len'] = train_data['question_text'].apply(len)\n","train_data.sample(frac=1).head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qas_id</th>\n","      <th>question_text</th>\n","      <th>doc_tokens</th>\n","      <th>orig_answer_text</th>\n","      <th>start_position</th>\n","      <th>end_position</th>\n","      <th>is_impossible</th>\n","      <th>paragraph_len</th>\n","      <th>question_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16983</th>\n","      <td>56e132ebcd28a01900c67699</td>\n","      <td>When Catalan reach Sardinia?</td>\n","      <td>[During, the, 11th, and, 12th, centuries, the,...</td>\n","      <td>14th century</td>\n","      <td>45</td>\n","      <td>46</td>\n","      <td>False</td>\n","      <td>59</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>47976</th>\n","      <td>571ab9fd4faf5e1900b8ac23</td>\n","      <td>What information is collected by Centers for M...</td>\n","      <td>[In, the, US,, starting, in, 2013,, under, the...</td>\n","      <td>financial relationships with physicians and ho...</td>\n","      <td>42</td>\n","      <td>47</td>\n","      <td>False</td>\n","      <td>75</td>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>43896</th>\n","      <td>570f887880d9841400ab35a3</td>\n","      <td>How is Victoria related to Elizabeth?</td>\n","      <td>[Elizabeth's, many, historic, visits, and, mee...</td>\n","      <td>great-great-grandmother</td>\n","      <td>77</td>\n","      <td>77</td>\n","      <td>False</td>\n","      <td>96</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>93998</th>\n","      <td>5a3ea0cb5a76c5001a3a83d7</td>\n","      <td>What happened to Palermo's population in the 1...</td>\n","      <td>[Sicily, fell, under, the, control, of, the, H...</td>\n","      <td></td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>True</td>\n","      <td>106</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>85183</th>\n","      <td>572812962ca10214002d9d42</td>\n","      <td>What aircraft did Steve Fossett use for his fl...</td>\n","      <td>[St., John's, was, the, starting, point, for, ...</td>\n","      <td>replica Vickers Vimy</td>\n","      <td>59</td>\n","      <td>61</td>\n","      <td>False</td>\n","      <td>81</td>\n","      <td>64</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         qas_id  ... question_len\n","16983  56e132ebcd28a01900c67699  ...           28\n","47976  571ab9fd4faf5e1900b8ac23  ...           74\n","43896  570f887880d9841400ab35a3  ...           37\n","93998  5a3ea0cb5a76c5001a3a83d7  ...           58\n","85183  572812962ca10214002d9d42  ...           64\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HLM4s-dKFPz","executionInfo":{"status":"ok","timestamp":1616497247937,"user_tz":-330,"elapsed":738,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"cb71d189-a4ce-451f-e855-0dc3c82ed629"},"source":["max_seq_length = 256\n","print(\"Percentage of context's less than max_seq_length = %s%%\" % (len([l for l in train_data['paragraph_len'] if l <= max_seq_length])/len(train_data) * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Percentage of context's less than max_seq_length = 98.19289589392184%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uaH4qmR9KMZV","executionInfo":{"status":"ok","timestamp":1616497249954,"user_tz":-330,"elapsed":1006,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"97c09736-e3cd-4882-bbb2-7b7c28be493b"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 4658285.39B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"R6LIojYQKRkh"},"source":["doc_stride = 128\n","max_seq_length = 256\n","max_query_length = 64\n","# batch size of 64 if RAM available.\n","batch_size = 16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uO1kFwZJKVFX"},"source":["cached_features_file = '/content/drive/MyDrive/Final-project/data/cache_train_new_25gb'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kOfNkqBKY1m","executionInfo":{"status":"ok","timestamp":1616497257849,"user_tz":-330,"elapsed":1077,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"9454cb44-ca68-43e7-e8a2-99d24f9c5866"},"source":["!ls /content/drive/MyDrive/Final-project/data/cache_train_new_25gb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Final-project/data/cache_train_new_25gb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pj5i8uXoKdV3"},"source":["if not os.path.exists(cached_features_file):\n","  features = convert_examples_to_features(examples=examples,\n","                                        tokenizer=tokenizer,\n","                                        max_seq_length=max_seq_length,\n","                                        doc_stride=doc_stride,\n","                                        max_query_length=max_query_length,\n","                                        is_training=True)\n","  torch.save(features, cached_features_file)\n","else:\n","  features = torch.load(cached_features_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYfrURmuKgP4"},"source":["def set_seed(seed=42):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zf0ZmOgGMoSI"},"source":["all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n","all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n","\n","all_start_positions = torch.tensor([f.start_position for f in features], dtype=torch.long)\n","all_end_positions = torch.tensor([f.end_position for f in features], dtype=torch.long)\n","dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n","                        all_start_positions, all_end_positions,\n","                        all_cls_index, all_p_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUML6GIgMrIK"},"source":["train_sampler = RandomSampler(dataset)\n","train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wlUi0ZANETE"},"source":["import glob\n","checkpoints = sorted(glob.glob('/content/drive/MyDrive/Final-project/temp/checkpoint*-[0-9]*'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S7ztkZsvNG29"},"source":["def to_list(tensor):\n","    return tensor.detach().cpu().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qP8d3ND8NJGv","executionInfo":{"status":"ok","timestamp":1616498450712,"user_tz":-330,"elapsed":18492,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"65633de2-3af6-446e-bbda-453b4cbb53c8"},"source":["if len(checkpoints) > 0:\n","  global_step = checkpoints[-1].split('-')[-1]\n","  print(global_step)\n","  ckpt_name = '/content/drive/MyDrive/Final-project/temp/checkpoint-{}'.format(global_step)\n","  # ckpt_name = '/content/drive/MyDrive/Final-project/temp/checkpoint-1500'\n","\n","  print(\"Loading model from checkpoint %s\" % ckpt_name)\n","  model = BertForQuestionAnswering.from_pretrained(ckpt_name)\n","  train_loss_set_ckpt = torch.load(ckpt_name + '/training_loss.pt')\n","  train_loss_set = to_list(train_loss_set_ckpt)\n","  tr_loss = train_loss_set[-1]\n","else:\n","  global_step = 0\n","  train_loss_set = []\n","  tr_loss = 0.0\n","  model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n","\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9000\n","Loading model from checkpoint /content/drive/MyDrive/Final-project/temp/checkpoint-9000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0kMCUGzNMwG","executionInfo":{"status":"ok","timestamp":1616498460264,"user_tz":-330,"elapsed":728,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"a3c4e4ef-d202-4a75-aae4-793c1f8a1aed"},"source":["param_optimizer = list(model.named_parameters())\n","print(param_optimizer[-2])\n","print(param_optimizer[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["('qa_outputs.weight', Parameter containing:\n","tensor([[ 0.0214,  0.0395, -0.0219,  ...,  0.0084, -0.0170,  0.0265],\n","        [ 0.0304,  0.0170, -0.0386,  ...,  0.0256,  0.0006,  0.0142]],\n","       device='cuda:0', requires_grad=True))\n","('qa_outputs.bias', Parameter containing:\n","tensor([0.0176, 0.0178], device='cuda:0', requires_grad=True))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCok8k5YNRLg"},"source":["learning_rate = 5e-5\n","adam_epsilon=1e-8\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_466_ilNams","executionInfo":{"status":"ok","timestamp":1616498464780,"user_tz":-330,"elapsed":721,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"6f94055e-3456-4cd2-be39-b5b50ad25fdd"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUJyH5VLNcXI","executionInfo":{"status":"ok","timestamp":1616498681123,"user_tz":-330,"elapsed":46729,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"d2de4848-f019-4afc-9458-b9882d6d4728"},"source":["num_train_epochs = 10\n","\n","print(\"***** Running training *****\")\n","print(\"  Num examples = %d\" % len(dataset))\n","print(\"  Num Epochs = %d\" % num_train_epochs)\n","print(\"  Batch size = %d\" % batch_size)\n","print(\"  Total optimization steps = %d\" % (len(train_dataloader) // num_train_epochs))\n","\n","model.zero_grad()\n","train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n","set_seed()\n","\n","for _ in train_iterator:\n","    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n","    for step, batch in enumerate(epoch_iterator):\n","      if step < int(global_step) + 1:\n","        continue\n","\n","      model.train()\n","      batch = tuple(t.to(device) for t in batch)\n","\n","      inputs = {'input_ids':       batch[0],\n","                'attention_mask':  batch[1], \n","                'token_type_ids':  batch[2],  \n","                'start_positions': batch[3], \n","                'end_positions':   batch[4]}\n","\n","      outputs = model(**inputs)\n","\n","      loss = outputs[0]\n","      train_loss_set.append(loss)\n","      loss.backward()\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      tr_loss += loss.item()\n","      optimizer.step()\n","      model.zero_grad()\n","      global_step = int(global_step)\n","      global_step += 1\n","    \n","      if global_step % 1000 == 0:\n","        print(\"Train loss: {}\".format(tr_loss/global_step))\n","        output_dir = '/content/drive/MyDrive/Final-project/temp/checkpoint-{}'.format(global_step)\n","        \n","        if not os.path.exists(output_dir):\n","            os.makedirs(output_dir)\n","        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(output_dir)\n","        torch.save(torch.tensor(train_loss_set), os.path.join(output_dir, 'training_loss.pt'))\n","        print(\"Saving model checkpoint to %s\" % output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   3%|▎         | 232/9016 [00:00<00:03, 2315.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 144262\n","  Num Epochs = 10\n","  Batch size = 16\n","  Total optimization steps = 901\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","Iteration:   5%|▍         | 436/9016 [00:00<00:03, 2224.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   7%|▋         | 631/9016 [00:00<00:03, 2131.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  10%|▉         | 877/9016 [00:00<00:03, 2218.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  12%|█▏        | 1110/9016 [00:00<00:03, 2249.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  15%|█▌        | 1355/9016 [00:00<00:03, 2305.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1605/9016 [00:00<00:03, 2359.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  20%|██        | 1848/9016 [00:00<00:03, 2379.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  23%|██▎       | 2097/9016 [00:00<00:02, 2409.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  26%|██▌       | 2334/9016 [00:01<00:02, 2396.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  29%|██▊       | 2577/9016 [00:01<00:02, 2403.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  31%|███       | 2814/9016 [00:01<00:02, 2221.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  34%|███▎      | 3036/9016 [00:01<00:02, 2193.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  36%|███▋      | 3290/9016 [00:01<00:02, 2287.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  39%|███▉      | 3539/9016 [00:01<00:02, 2342.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  42%|████▏     | 3775/9016 [00:01<00:02, 2197.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  45%|████▍     | 4020/9016 [00:01<00:02, 2267.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  47%|████▋     | 4278/9016 [00:01<00:02, 2351.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  50%|█████     | 4529/9016 [00:01<00:01, 2395.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  53%|█████▎    | 4783/9016 [00:02<00:01, 2436.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  56%|█████▌    | 5029/9016 [00:02<00:01, 2331.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  58%|█████▊    | 5265/9016 [00:02<00:01, 2152.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  61%|██████    | 5485/9016 [00:02<00:01, 2065.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  64%|██████▎   | 5736/9016 [00:02<00:01, 2180.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  66%|██████▋   | 5978/9016 [00:02<00:01, 2247.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  69%|██████▉   | 6225/9016 [00:02<00:01, 2308.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  72%|███████▏  | 6475/9016 [00:02<00:01, 2361.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  74%|███████▍  | 6714/9016 [00:02<00:00, 2349.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  77%|███████▋  | 6958/9016 [00:03<00:00, 2375.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  80%|███████▉  | 7199/9016 [00:03<00:00, 2385.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  83%|████████▎ | 7439/9016 [00:03<00:00, 2252.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  85%|████████▌ | 7667/9016 [00:03<00:00, 2245.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  88%|████████▊ | 7918/9016 [00:03<00:00, 2317.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  91%|█████████ | 8160/9016 [00:03<00:00, 2344.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  93%|█████████▎| 8416/9016 [00:03<00:00, 2402.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  96%|█████████▌| 8672/9016 [00:03<00:00, 2443.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:10<00:00, 841.07it/s] \n","\n","\n","\n","\n","Epoch:  10%|█         | 1/10 [00:10<01:36, 10.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   3%|▎         | 228/9016 [00:00<00:03, 2278.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▍         | 416/9016 [00:00<00:04, 2141.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   7%|▋         | 669/9016 [00:00<00:03, 2243.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  10%|▉         | 887/9016 [00:00<00:03, 2222.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1141/9016 [00:00<00:03, 2308.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  15%|█▌        | 1384/9016 [00:00<00:03, 2343.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1624/9016 [00:00<00:03, 2359.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  20%|██        | 1843/9016 [00:00<00:03, 2144.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  23%|██▎       | 2084/9016 [00:00<00:03, 2215.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  26%|██▌       | 2332/9016 [00:01<00:02, 2287.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  29%|██▊       | 2582/9016 [00:01<00:02, 2345.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  31%|███▏      | 2835/9016 [00:01<00:02, 2397.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  34%|███▍      | 3088/9016 [00:01<00:02, 2435.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  37%|███▋      | 3341/9016 [00:01<00:02, 2461.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  40%|███▉      | 3596/9016 [00:01<00:02, 2486.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  43%|████▎     | 3845/9016 [00:01<00:02, 2475.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  45%|████▌     | 4093/9016 [00:01<00:02, 2447.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  48%|████▊     | 4346/9016 [00:01<00:01, 2469.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  51%|█████     | 4594/9016 [00:01<00:01, 2469.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  54%|█████▎    | 4841/9016 [00:02<00:01, 2459.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  56%|█████▋    | 5088/9016 [00:02<00:01, 2444.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  59%|█████▉    | 5336/9016 [00:02<00:01, 2453.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  62%|██████▏   | 5583/9016 [00:02<00:01, 2455.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  65%|██████▍   | 5837/9016 [00:02<00:01, 2480.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  68%|██████▊   | 6095/9016 [00:02<00:01, 2506.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  70%|███████   | 6351/9016 [00:02<00:01, 2521.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  73%|███████▎  | 6604/9016 [00:02<00:00, 2507.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  76%|███████▌  | 6855/9016 [00:02<00:00, 2471.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  79%|███████▉  | 7103/9016 [00:02<00:00, 2473.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  82%|████████▏ | 7361/9016 [00:03<00:00, 2503.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  84%|████████▍ | 7612/9016 [00:03<00:00, 2482.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  87%|████████▋ | 7861/9016 [00:03<00:00, 2424.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  90%|████████▉ | 8113/9016 [00:03<00:00, 2450.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  93%|█████████▎| 8368/9016 [00:03<00:00, 2478.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  96%|█████████▌| 8617/9016 [00:03<00:00, 2355.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2407.67it/s]\n","\n","\n","\n","\n","Epoch:  20%|██        | 2/10 [00:14<01:09,  8.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   3%|▎         | 235/9016 [00:00<00:03, 2343.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▌         | 465/9016 [00:00<00:03, 2328.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   8%|▊         | 716/9016 [00:00<00:03, 2377.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  11%|█         | 956/9016 [00:00<00:03, 2382.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1208/9016 [00:00<00:03, 2418.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  16%|█▌        | 1463/9016 [00:00<00:03, 2456.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  19%|█▊        | 1682/9016 [00:00<00:03, 2321.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  21%|██        | 1897/9016 [00:00<00:03, 2130.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  23%|██▎       | 2101/9016 [00:00<00:03, 2044.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  26%|██▌       | 2300/9016 [00:01<00:03, 1947.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  28%|██▊       | 2494/9016 [00:01<00:03, 1941.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  30%|██▉       | 2687/9016 [00:01<00:03, 1916.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  32%|███▏      | 2881/9016 [00:01<00:03, 1921.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  34%|███▍      | 3074/9016 [00:01<00:03, 1922.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  36%|███▌      | 3266/9016 [00:01<00:02, 1918.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  39%|███▉      | 3517/9016 [00:01<00:02, 2062.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  42%|████▏     | 3763/9016 [00:01<00:02, 2165.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  45%|████▍     | 4015/9016 [00:01<00:02, 2259.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  47%|████▋     | 4268/9016 [00:01<00:02, 2334.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  50%|████▉     | 4505/9016 [00:02<00:01, 2328.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  53%|█████▎    | 4740/9016 [00:02<00:01, 2334.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  55%|█████▌    | 4991/9016 [00:02<00:01, 2383.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  58%|█████▊    | 5245/9016 [00:02<00:01, 2427.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  61%|██████    | 5505/9016 [00:02<00:01, 2475.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  64%|██████▍   | 5754/9016 [00:02<00:01, 2438.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  67%|██████▋   | 6000/9016 [00:02<00:01, 2445.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  69%|██████▉   | 6258/9016 [00:02<00:01, 2482.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  72%|███████▏  | 6507/9016 [00:02<00:01, 2464.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  75%|███████▍  | 6758/9016 [00:02<00:00, 2475.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  78%|███████▊  | 7006/9016 [00:03<00:00, 2455.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  81%|████████  | 7265/9016 [00:03<00:00, 2493.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  83%|████████▎ | 7523/9016 [00:03<00:00, 2517.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  86%|████████▌ | 7776/9016 [00:03<00:00, 2497.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  89%|████████▉ | 8031/9016 [00:03<00:00, 2511.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  92%|█████████▏| 8283/9016 [00:03<00:00, 2477.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  95%|█████████▍| 8532/9016 [00:03<00:00, 2470.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2317.16it/s]\n","\n","\n","\n","\n","Epoch:  30%|███       | 3/10 [00:18<00:50,  7.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   2%|▏         | 162/9016 [00:00<00:05, 1614.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▍         | 414/9016 [00:00<00:04, 1808.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   7%|▋         | 664/9016 [00:00<00:04, 1971.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  10%|█         | 924/9016 [00:00<00:03, 2125.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1178/9016 [00:00<00:03, 2233.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  16%|█▌        | 1436/9016 [00:00<00:03, 2326.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  19%|█▊        | 1672/9016 [00:00<00:03, 2335.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  21%|██        | 1898/9016 [00:00<00:03, 2260.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  24%|██▍       | 2160/9016 [00:00<00:02, 2357.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  27%|██▋       | 2414/9016 [00:01<00:02, 2408.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  30%|██▉       | 2664/9016 [00:01<00:02, 2432.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  32%|███▏      | 2909/9016 [00:01<00:02, 2433.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  35%|███▍      | 3152/9016 [00:01<00:02, 2196.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  38%|███▊      | 3402/9016 [00:01<00:02, 2277.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  41%|████      | 3656/9016 [00:01<00:02, 2349.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  43%|████▎     | 3911/9016 [00:01<00:02, 2404.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  46%|████▌     | 4168/9016 [00:01<00:01, 2450.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  49%|████▉     | 4415/9016 [00:01<00:01, 2407.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  52%|█████▏    | 4658/9016 [00:01<00:01, 2222.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  54%|█████▍    | 4907/9016 [00:02<00:01, 2295.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  57%|█████▋    | 5147/9016 [00:02<00:01, 2325.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  60%|█████▉    | 5394/9016 [00:02<00:01, 2364.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  63%|██████▎   | 5651/9016 [00:02<00:01, 2421.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  65%|██████▌   | 5895/9016 [00:02<00:01, 2407.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  68%|██████▊   | 6137/9016 [00:02<00:01, 2358.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  71%|███████   | 6392/9016 [00:02<00:01, 2412.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  74%|███████▎  | 6635/9016 [00:02<00:00, 2388.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  76%|███████▋  | 6875/9016 [00:02<00:00, 2235.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  79%|███████▉  | 7102/9016 [00:03<00:00, 2091.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  81%|████████▏ | 7340/9016 [00:03<00:00, 2169.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  84%|████████▍ | 7584/9016 [00:03<00:00, 2242.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  87%|████████▋ | 7833/9016 [00:03<00:00, 2310.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  90%|████████▉ | 8083/9016 [00:03<00:00, 2361.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  92%|█████████▏| 8324/9016 [00:03<00:00, 2373.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  95%|█████████▍| 8564/9016 [00:03<00:00, 2378.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2350.41it/s]\n","\n","\n","\n","\n","Epoch:  40%|████      | 4/10 [00:22<00:37,  6.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   2%|▏         | 217/9016 [00:00<00:04, 2168.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▌         | 466/9016 [00:00<00:03, 2255.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   8%|▊         | 691/9016 [00:00<00:03, 2252.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  10%|█         | 937/9016 [00:00<00:03, 2309.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1189/9016 [00:00<00:03, 2367.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  16%|█▌        | 1434/9016 [00:00<00:03, 2389.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1649/9016 [00:00<00:03, 2164.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  21%|██        | 1872/9016 [00:00<00:03, 2183.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  23%|██▎       | 2096/9016 [00:00<00:03, 2198.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  26%|██▌       | 2310/9016 [00:01<00:03, 2149.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  28%|██▊       | 2521/9016 [00:01<00:03, 2025.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  31%|███       | 2770/9016 [00:01<00:02, 2145.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  33%|███▎      | 3013/9016 [00:01<00:02, 2221.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  36%|███▌      | 3264/9016 [00:01<00:02, 2297.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  39%|███▉      | 3502/9016 [00:01<00:02, 2318.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  41%|████▏     | 3740/9016 [00:01<00:02, 2336.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  44%|████▍     | 3987/9016 [00:01<00:02, 2373.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  47%|████▋     | 4226/9016 [00:01<00:02, 2252.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  50%|████▉     | 4467/9016 [00:01<00:01, 2296.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  52%|█████▏    | 4710/9016 [00:02<00:01, 2332.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  55%|█████▌    | 4966/9016 [00:02<00:01, 2393.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  58%|█████▊    | 5219/9016 [00:02<00:01, 2430.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  61%|██████    | 5464/9016 [00:02<00:01, 2405.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  63%|██████▎   | 5718/9016 [00:02<00:01, 2444.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  66%|██████▌   | 5972/9016 [00:02<00:01, 2471.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  69%|██████▉   | 6220/9016 [00:02<00:01, 2454.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  72%|███████▏  | 6466/9016 [00:02<00:01, 2373.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  74%|███████▍  | 6705/9016 [00:02<00:01, 2257.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  77%|███████▋  | 6959/9016 [00:03<00:00, 2335.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  80%|███████▉  | 7195/9016 [00:03<00:00, 2272.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  82%|████████▏ | 7424/9016 [00:03<00:00, 2276.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  85%|████████▍ | 7663/9016 [00:03<00:00, 2306.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  88%|████████▊ | 7898/9016 [00:03<00:00, 2316.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  90%|█████████ | 8144/9016 [00:03<00:00, 2356.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  93%|█████████▎| 8383/9016 [00:03<00:00, 2365.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  96%|█████████▌| 8629/9016 [00:03<00:00, 2391.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2316.61it/s]\n","\n","\n","\n","\n","Epoch:  50%|█████     | 5/10 [00:26<00:27,  5.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   2%|▏         | 157/9016 [00:00<00:05, 1564.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   4%|▍         | 384/9016 [00:00<00:05, 1724.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   6%|▋         | 573/9016 [00:00<00:04, 1769.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   9%|▉         | 800/9016 [00:00<00:04, 1894.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  11%|█▏        | 1031/9016 [00:00<00:03, 2000.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  14%|█▎        | 1223/9016 [00:00<00:03, 1974.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  16%|█▌        | 1406/9016 [00:00<00:03, 1924.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1651/9016 [00:00<00:03, 2056.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  21%|██        | 1897/9016 [00:00<00:03, 2161.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  24%|██▍       | 2152/9016 [00:01<00:03, 2264.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  27%|██▋       | 2391/9016 [00:01<00:02, 2299.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  29%|██▉       | 2634/9016 [00:01<00:02, 2336.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  32%|███▏      | 2889/9016 [00:01<00:02, 2395.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  35%|███▍      | 3146/9016 [00:01<00:02, 2443.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  38%|███▊      | 3394/9016 [00:01<00:02, 2452.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  40%|████      | 3640/9016 [00:01<00:02, 2429.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  43%|████▎     | 3888/9016 [00:01<00:02, 2443.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  46%|████▌     | 4149/9016 [00:01<00:01, 2489.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  49%|████▉     | 4399/9016 [00:01<00:01, 2467.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  52%|█████▏    | 4647/9016 [00:02<00:01, 2309.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  54%|█████▍    | 4881/9016 [00:02<00:01, 2262.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  57%|█████▋    | 5135/9016 [00:02<00:01, 2337.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  60%|█████▉    | 5377/9016 [00:02<00:01, 2360.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  62%|██████▏   | 5619/9016 [00:02<00:01, 2376.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  65%|██████▌   | 5861/9016 [00:02<00:01, 2388.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  68%|██████▊   | 6107/9016 [00:02<00:01, 2408.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  71%|███████   | 6358/9016 [00:02<00:01, 2437.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  73%|███████▎  | 6603/9016 [00:02<00:01, 2383.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  76%|███████▌  | 6842/9016 [00:02<00:00, 2239.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  78%|███████▊  | 7069/9016 [00:03<00:00, 2171.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  81%|████████  | 7319/9016 [00:03<00:00, 2259.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  84%|████████▍ | 7561/9016 [00:03<00:00, 2304.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  87%|████████▋ | 7819/9016 [00:03<00:00, 2378.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  89%|████████▉ | 8059/9016 [00:03<00:00, 2362.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  92%|█████████▏| 8299/9016 [00:03<00:00, 2371.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  95%|█████████▍| 8546/9016 [00:03<00:00, 2399.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2306.29it/s]\n","\n","\n","\n","\n","Epoch:  60%|██████    | 6/10 [00:30<00:20,  5.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   3%|▎         | 228/9016 [00:00<00:03, 2274.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▌         | 469/9016 [00:00<00:03, 2311.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   8%|▊         | 709/9016 [00:00<00:03, 2336.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  11%|█         | 964/9016 [00:00<00:03, 2395.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1205/9016 [00:00<00:03, 2396.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  16%|█▌        | 1407/9016 [00:00<00:03, 2266.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1651/9016 [00:00<00:03, 2314.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  21%|██        | 1889/9016 [00:00<00:03, 2331.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  24%|██▍       | 2142/9016 [00:00<00:02, 2387.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  27%|██▋       | 2393/9016 [00:01<00:02, 2421.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  29%|██▉       | 2630/9016 [00:01<00:02, 2385.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  32%|███▏      | 2873/9016 [00:01<00:02, 2398.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  35%|███▍      | 3114/9016 [00:01<00:02, 2400.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  37%|███▋      | 3369/9016 [00:01<00:02, 2441.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  40%|████      | 3613/9016 [00:01<00:02, 2385.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  43%|████▎     | 3860/9016 [00:01<00:02, 2408.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  46%|████▌     | 4116/9016 [00:01<00:01, 2451.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  48%|████▊     | 4362/9016 [00:01<00:01, 2420.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  51%|█████     | 4611/9016 [00:01<00:01, 2437.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  54%|█████▍    | 4855/9016 [00:02<00:01, 2273.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  57%|█████▋    | 5101/9016 [00:02<00:01, 2325.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  59%|█████▉    | 5350/9016 [00:02<00:01, 2372.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  62%|██████▏   | 5600/9016 [00:02<00:01, 2406.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  65%|██████▍   | 5849/9016 [00:02<00:01, 2428.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  68%|██████▊   | 6093/9016 [00:02<00:01, 2406.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  70%|███████   | 6337/9016 [00:02<00:01, 2415.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  73%|███████▎  | 6590/9016 [00:02<00:00, 2447.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  76%|███████▌  | 6836/9016 [00:02<00:00, 2443.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  79%|███████▊  | 7081/9016 [00:02<00:00, 2288.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  81%|████████  | 7314/9016 [00:03<00:00, 2298.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  84%|████████▍ | 7566/9016 [00:03<00:00, 2360.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  87%|████████▋ | 7809/9016 [00:03<00:00, 2378.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  89%|████████▉ | 8052/9016 [00:03<00:00, 2391.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  92%|█████████▏| 8292/9016 [00:03<00:00, 2382.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  95%|█████████▍| 8540/9016 [00:03<00:00, 2410.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2390.10it/s]\n","\n","\n","\n","\n","Epoch:  70%|███████   | 7/10 [00:33<00:13,  4.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   2%|▏         | 220/9016 [00:00<00:04, 2197.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▌         | 467/9016 [00:00<00:03, 2271.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   8%|▊         | 700/9016 [00:00<00:03, 2287.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  10%|█         | 925/9016 [00:00<00:03, 2275.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1143/9016 [00:00<00:03, 2244.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  15%|█▌        | 1383/9016 [00:00<00:03, 2287.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1599/9016 [00:00<00:03, 2246.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  20%|██        | 1832/9016 [00:00<00:03, 2270.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  23%|██▎       | 2047/9016 [00:00<00:03, 2093.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  25%|██▍       | 2251/9016 [00:01<00:03, 2021.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  27%|██▋       | 2450/9016 [00:01<00:03, 1968.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  29%|██▉       | 2645/9016 [00:01<00:03, 1937.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  32%|███▏      | 2855/9016 [00:01<00:03, 1982.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  34%|███▍      | 3053/9016 [00:01<00:03, 1917.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  36%|███▌      | 3254/9016 [00:01<00:02, 1943.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  38%|███▊      | 3449/9016 [00:01<00:02, 1911.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  40%|████      | 3641/9016 [00:01<00:02, 1878.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  43%|████▎     | 3880/9016 [00:01<00:02, 2005.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  45%|████▌     | 4084/9016 [00:01<00:02, 1946.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  47%|████▋     | 4281/9016 [00:02<00:02, 1932.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  50%|████▉     | 4476/9016 [00:02<00:02, 1916.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  52%|█████▏    | 4706/9016 [00:02<00:02, 2017.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  55%|█████▍    | 4943/9016 [00:02<00:01, 2110.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  57%|█████▋    | 5169/9016 [00:02<00:01, 2153.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  60%|█████▉    | 5387/9016 [00:02<00:01, 2147.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  62%|██████▏   | 5604/9016 [00:02<00:01, 2095.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  65%|██████▍   | 5843/9016 [00:02<00:01, 2175.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  67%|██████▋   | 6063/9016 [00:02<00:01, 2071.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  70%|██████▉   | 6303/9016 [00:03<00:01, 2158.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  73%|███████▎  | 6543/9016 [00:03<00:01, 2223.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  75%|███████▌  | 6803/9016 [00:03<00:00, 2321.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  78%|███████▊  | 7045/9016 [00:03<00:00, 2348.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  81%|████████  | 7282/9016 [00:03<00:00, 2355.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  83%|████████▎ | 7525/9016 [00:03<00:00, 2375.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  86%|████████▌ | 7764/9016 [00:03<00:00, 2376.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  89%|████████▉ | 8014/9016 [00:03<00:00, 2411.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  92%|█████████▏| 8256/9016 [00:03<00:00, 2393.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  94%|█████████▍| 8496/9016 [00:03<00:00, 2380.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  97%|█████████▋| 8735/9016 [00:04<00:00, 2380.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:04<00:00, 2175.28it/s]\n","\n","\n","\n","\n","Epoch:  80%|████████  | 8/10 [00:37<00:09,  4.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   3%|▎         | 228/9016 [00:00<00:03, 2276.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▌         | 459/9016 [00:00<00:03, 2283.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   8%|▊         | 693/9016 [00:00<00:03, 2297.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  10%|█         | 938/9016 [00:00<00:03, 2339.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  13%|█▎        | 1168/9016 [00:00<00:03, 2327.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  16%|█▌        | 1414/9016 [00:00<00:03, 2363.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  18%|█▊        | 1659/9016 [00:00<00:03, 2388.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  21%|██        | 1880/9016 [00:00<00:03, 2157.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  23%|██▎       | 2088/9016 [00:00<00:03, 2066.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  25%|██▌       | 2290/9016 [00:01<00:03, 2039.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  28%|██▊       | 2497/9016 [00:01<00:03, 2046.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  30%|██▉       | 2700/9016 [00:01<00:03, 1969.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  33%|███▎      | 2942/9016 [00:01<00:02, 2084.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  35%|███▍      | 3152/9016 [00:01<00:02, 2026.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  38%|███▊      | 3388/9016 [00:01<00:02, 2114.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  40%|████      | 3638/9016 [00:01<00:02, 2215.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  43%|████▎     | 3870/9016 [00:01<00:02, 2244.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  46%|████▌     | 4105/9016 [00:01<00:02, 2272.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  48%|████▊     | 4340/9016 [00:01<00:02, 2295.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  51%|█████     | 4591/9016 [00:02<00:01, 2355.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  54%|█████▎    | 4828/9016 [00:02<00:01, 2303.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  56%|█████▋    | 5080/9016 [00:02<00:01, 2362.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  59%|█████▉    | 5318/9016 [00:02<00:01, 2351.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  62%|██████▏   | 5554/9016 [00:02<00:01, 2246.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  64%|██████▍   | 5787/9016 [00:02<00:01, 2269.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  67%|██████▋   | 6032/9016 [00:02<00:01, 2320.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  70%|██████▉   | 6274/9016 [00:02<00:01, 2348.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  72%|███████▏  | 6522/9016 [00:02<00:01, 2384.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  75%|███████▌  | 6762/9016 [00:02<00:00, 2382.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  78%|███████▊  | 7007/9016 [00:03<00:00, 2400.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  80%|████████  | 7249/9016 [00:03<00:00, 2405.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  83%|████████▎ | 7490/9016 [00:03<00:00, 2399.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  86%|████████▌ | 7731/9016 [00:03<00:00, 2382.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  89%|████████▊ | 7980/9016 [00:03<00:00, 2413.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  91%|█████████ | 8222/9016 [00:03<00:00, 2394.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  94%|█████████▍| 8470/9016 [00:03<00:00, 2419.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  97%|█████████▋| 8713/9016 [00:03<00:00, 2392.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2290.78it/s]\n","\n","\n","\n","\n","Epoch:  90%|█████████ | 9/10 [00:41<00:04,  4.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   0%|          | 0/9016 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   2%|▏         | 173/9016 [00:00<00:05, 1728.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   5%|▍         | 420/9016 [00:00<00:04, 1899.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   7%|▋         | 596/9016 [00:00<00:04, 1853.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:   9%|▉         | 835/9016 [00:00<00:04, 1985.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  12%|█▏        | 1068/9016 [00:00<00:03, 2077.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  15%|█▍        | 1308/9016 [00:00<00:03, 2163.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  17%|█▋        | 1559/9016 [00:00<00:03, 2255.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  20%|█▉        | 1797/9016 [00:00<00:03, 2291.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  22%|██▏       | 2020/9016 [00:00<00:03, 2135.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  25%|██▌       | 2259/9016 [00:01<00:03, 2204.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  28%|██▊       | 2511/9016 [00:01<00:02, 2288.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  30%|███       | 2741/9016 [00:01<00:02, 2291.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  33%|███▎      | 2971/9016 [00:01<00:02, 2108.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  36%|███▌      | 3226/9016 [00:01<00:02, 2222.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  39%|███▊      | 3479/9016 [00:01<00:02, 2305.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  41%|████      | 3715/9016 [00:01<00:02, 2319.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  44%|████▍     | 3968/9016 [00:01<00:02, 2379.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  47%|████▋     | 4208/9016 [00:01<00:02, 2357.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  49%|████▉     | 4446/9016 [00:01<00:01, 2355.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  52%|█████▏    | 4689/9016 [00:02<00:01, 2374.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  55%|█████▍    | 4941/9016 [00:02<00:01, 2413.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  57%|█████▋    | 5184/9016 [00:02<00:01, 2269.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  60%|██████    | 5429/9016 [00:02<00:01, 2319.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  63%|██████▎   | 5665/9016 [00:02<00:01, 2330.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  66%|██████▌   | 5908/9016 [00:02<00:01, 2358.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  68%|██████▊   | 6145/9016 [00:02<00:01, 2334.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  71%|███████   | 6389/9016 [00:02<00:01, 2363.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  73%|███████▎  | 6626/9016 [00:02<00:01, 2358.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  76%|███████▌  | 6866/9016 [00:02<00:00, 2370.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  79%|███████▉  | 7109/9016 [00:03<00:00, 2388.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  82%|████████▏ | 7349/9016 [00:03<00:00, 2320.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  84%|████████▍ | 7582/9016 [00:03<00:00, 2231.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  87%|████████▋ | 7810/9016 [00:03<00:00, 2243.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  89%|████████▉ | 8059/9016 [00:03<00:00, 2311.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  92%|█████████▏| 8294/9016 [00:03<00:00, 2321.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  95%|█████████▍| 8527/9016 [00:03<00:00, 2302.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration:  97%|█████████▋| 8758/9016 [00:03<00:00, 2170.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Iteration: 100%|██████████| 9016/9016 [00:03<00:00, 2267.37it/s]\n","\n","\n","\n","\n","Epoch: 100%|██████████| 10/10 [00:45<00:00,  4.59s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8qINOTxJU23J"},"source":["output_dir = '/drive/My Drive/Final-project/temp/'\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","model_to_save = model.module if hasattr(model, 'module') else model\n","model_to_save.save_pretrained(output_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Gc1dZgx6jE_"},"source":["output_dir = '/content/drive/MyDrive/Final-project/temp/checkpoint-final\n","        \n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","torch.save(torch.tensor(train_loss_set), os.path.join(output_dir, 'training_loss.pt'))\n","print(\"Saving model checkpoint to %s\" % output_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHXZ801ob-FI"},"source":["torch.save(model,'/drive/My Drive/Final-project/temp/final-saved-model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTaR6AqJ1a1J"},"source":["# model.save()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFP-F5F_U73l"},"source":["# train_loss_set_ckpt = torch.load('/drive/My Drive/Final-project/temp/checkpoint-final/training_loss.pt')\n","# train_loss_set = to_list(train_loss_set_ckpt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUB-KCqsU81E"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y92nJUqwU84E"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZeNgo0PU87r"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TPNPboNN7OI"},"source":["train_loss_set_ckpt = torch.load('/content/drive/MyDrive/Final-project/temp/checkpoint-9000/training_loss.pt')\n","train_loss_set = to_list(train_loss_set_ckpt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"n_jFwOKpeCHA","executionInfo":{"status":"ok","timestamp":1616498985759,"user_tz":-330,"elapsed":1036,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"0436fafc-0fc1-4cc6-e3c2-da41b07bd3f9"},"source":["plt.figure(figsize=(15,8))\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Batch\")\n","plt.ylabel(\"Loss\")\n","plt.plot(train_loss_set)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"rvftBifcelVI"},"source":["### Load Test Dataset"]},{"cell_type":"code","metadata":{"id":"LD-a7qUkecrg"},"source":["input_file = '/content/drive/MyDrive/Final-project/data/dev-v2.0.json'\n","val_examples = read_squad_examples(input_file=input_file,\n","                                is_training=False,\n","                                version_2_with_negative=True)\n","doc_stride = 128\n","max_seq_length = 256\n","max_query_length = 64\n","cached_features_file = '/content/drive/MyDrive/Final-project/data/cache_validation'\n","\n","# Cache features for faster loading\n","if not os.path.exists(cached_features_file):\n","  features = convert_examples_to_features(examples=val_examples,\n","                                        tokenizer=tokenizer,\n","                                        max_seq_length=max_seq_length,\n","                                        doc_stride=doc_stride,\n","                                        max_query_length=max_query_length,\n","                                        is_training=False)\n","  torch.save(features, cached_features_file)\n","else:\n","  features = torch.load(cached_features_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LUci10bAepNu"},"source":["# Convert to Tensors and build dataset\n","all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n","all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n","\n","all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n","dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n","                        all_example_index, all_cls_index, all_p_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVrDfCWSe_Sv"},"source":["validation_sampler = SequentialSampler(dataset)\n","validation_dataloader = DataLoader(dataset, sampler=validation_sampler, batch_size=batch_size, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xPh--csfCNc"},"source":["def  (model, tokenizer):\n","  print(\"***** Running evaluation *****\")\n","  print(\"  Num examples = %d\" % len(dataset))\n","  print(\"  Batch size = %d\" % batch_size)\n","  all_results = []\n","  predict_file = '/content/drive/MyDrive/Final-project/data/dev-v2.0.json'\n","  for batch in tqdm(validation_dataloader, desc=\"Evaluating\", miniters=100, mininterval=5.0):\n","    model.eval()\n","    batch = tuple(t.to(device) for t in batch)\n","    with torch.no_grad():\n","      inputs = {'input_ids':      batch[0],\n","                'attention_mask': batch[1],\n","                'token_type_ids': batch[2]\n","                }\n","      example_indices = batch[3]\n","      outputs = model(**inputs)\n","\n","    for i, example_index in enumerate(example_indices):\n","      eval_feature = features[example_index.item()]\n","      unique_id = int(eval_feature.unique_id)\n","\n","      result = RawResult(unique_id    = unique_id,\n","                         start_logits = to_list(outputs[0][i]),\n","                         end_logits   = to_list(outputs[1][i]))\n","      all_results.append(result)\n","\n","  # Compute predictions\n","  output_prediction_file = \"/content/drive/MyDrive/Final-project/data/Bertprediction/predictions.json\"\n","  output_nbest_file = \"/content/drive/MyDrive/Final-project/data/Bertprediction/nbest_predictions.json\"\n","  output_null_log_odds_file = \"/content/drive/MyDrive/Final-project/data/Bertprediction/null_odds.json\"\n","  output_dir = \"/content/drive/MyDrive/Final-project/data/Bertprediction/predict_results\"\n","\n","  write_predictions(val_examples, features, all_results, 100,\n","                  30, True, output_prediction_file,\n","                  output_nbest_file, output_null_log_odds_file, False,\n","                  True, 0.0)\n","\n","  # Evaluate with the official SQuAD script\n","  evaluate_options = EVAL_OPTS(data_file=predict_file,\n","                               pred_file=output_prediction_file,\n","                               na_prob_file=output_null_log_odds_file,\n","                               out_image_dir=None)\n","  results = main(evaluate_options)\n","  return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UnJ4DhnfHIw","executionInfo":{"status":"ok","timestamp":1616500049336,"user_tz":-330,"elapsed":508302,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"c185145f-ab24-4c67-c69f-71ecaaa2b6ba"},"source":["results = evaluate(model, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","Evaluating:   0%|          | 0/850 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["***** Running evaluation *****\n","  Num examples = 13600\n","  Batch size = 16\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","Evaluating:  12%|█▏        | 100/850 [00:14<01:48,  6.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  12%|█▏        | 100/850 [00:28<01:48,  6.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  24%|██▎       | 200/850 [00:28<01:33,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  28%|██▊       | 235/850 [00:33<01:28,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  32%|███▏      | 270/850 [00:39<01:23,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  36%|███▌      | 305/850 [00:44<01:18,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  40%|████      | 340/850 [00:49<01:13,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  44%|████▍     | 375/850 [00:54<01:08,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  48%|████▊     | 410/850 [00:59<01:03,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  52%|█████▏    | 445/850 [01:04<00:58,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  56%|█████▋    | 480/850 [01:09<00:53,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  61%|██████    | 515/850 [01:14<00:48,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  65%|██████▍   | 550/850 [01:19<00:43,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  69%|██████▉   | 585/850 [01:24<00:38,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  73%|███████▎  | 620/850 [01:29<00:33,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  77%|███████▋  | 655/850 [01:34<00:28,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  81%|████████  | 690/850 [01:39<00:23,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  85%|████████▌ | 725/850 [01:44<00:18,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  89%|████████▉ | 760/850 [01:49<00:12,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  94%|█████████▎| 795/850 [01:54<00:07,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating: 100%|██████████| 850/850 [02:02<00:00,  6.93it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{\n","  \"exact\": 66.72281647435358,\n","  \"f1\": 70.51353411307717,\n","  \"total\": 11873,\n","  \"HasAns_exact\": 71.7948717948718,\n","  \"HasAns_f1\": 79.38717788875893,\n","  \"HasAns_total\": 5928,\n","  \"NoAns_exact\": 61.665264928511355,\n","  \"NoAns_f1\": 61.665264928511355,\n","  \"NoAns_total\": 5945,\n","  \"best_exact\": 70.5803082624442,\n","  \"best_exact_thresh\": -4.600459337234497,\n","  \"best_f1\": 73.24828544351521,\n","  \"best_f1_thresh\": -3.4874069690704346\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d9sGagkTfOgK"},"source":["# device = torch.device(\"cuda\")\n","# path = '/content/drive/MyDrive/Final-project/temp/checkpoint-9000/pytorch_model.bin'\n","# model1 = torch.load(path)\n","# model1.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DchK9Shti0Z2","executionInfo":{"status":"ok","timestamp":1616500289410,"user_tz":-330,"elapsed":5126,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"b610e064-f469-4dbd-8cd9-e25052ef3e28"},"source":["device = torch.device(\"cuda\")\n","ckpt_name = '/content/drive/MyDrive/Final-project/temp/checkpoint-9000'\n","print(\"Loading model from checkpoint %s\" % ckpt_name)\n","model_trained = BertForQuestionAnswering.from_pretrained(ckpt_name)\n","model_trained.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading model from checkpoint /content/drive/MyDrive/Final-project/temp/checkpoint-9000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6gc2d1HoaAR","executionInfo":{"status":"ok","timestamp":1616500809824,"user_tz":-330,"elapsed":505586,"user":{"displayName":"MrRobot TheBot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjMb-gsEIUeJx3ohafYDItfAt41SXF1VPqs5XlF=s64","userId":"13571716785643082615"}},"outputId":"9ee1a666-7ea7-474b-9439-f5e2408d760e"},"source":["results2 = evaluate(model_trained, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","Evaluating:   0%|          | 0/850 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["***** Running evaluation *****\n","  Num examples = 13600\n","  Batch size = 16\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","Evaluating:  12%|█▏        | 100/850 [00:14<01:48,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  12%|█▏        | 100/850 [00:26<01:48,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  22%|██▏       | 186/850 [00:26<01:35,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  26%|██▌       | 221/850 [00:31<01:30,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  30%|███       | 256/850 [00:36<01:25,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  34%|███▍      | 291/850 [00:42<01:20,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  38%|███▊      | 326/850 [00:47<01:15,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  42%|████▏     | 361/850 [00:52<01:10,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  47%|████▋     | 396/850 [00:57<01:05,  6.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  51%|█████     | 431/850 [01:02<01:00,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  55%|█████▍    | 466/850 [01:07<00:55,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  59%|█████▉    | 501/850 [01:12<00:50,  6.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  63%|██████▎   | 536/850 [01:17<00:45,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  67%|██████▋   | 571/850 [01:22<00:40,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  71%|███████▏  | 606/850 [01:27<00:35,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  75%|███████▌  | 641/850 [01:32<00:30,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  80%|███████▉  | 676/850 [01:37<00:25,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  84%|████████▎ | 711/850 [01:42<00:20,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  88%|████████▊ | 746/850 [01:47<00:15,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  92%|█████████▏| 781/850 [01:52<00:09,  6.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating:  95%|█████████▌| 810/850 [01:57<00:06,  6.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Evaluating: 100%|██████████| 850/850 [02:03<00:00,  6.88it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{\n","  \"exact\": 69.93177798366041,\n","  \"f1\": 73.0707059516954,\n","  \"total\": 11873,\n","  \"HasAns_exact\": 63.782051282051285,\n","  \"HasAns_f1\": 70.0689088671521,\n","  \"HasAns_total\": 5928,\n","  \"NoAns_exact\": 76.06391925988225,\n","  \"NoAns_f1\": 76.06391925988225,\n","  \"NoAns_total\": 5945,\n","  \"best_exact\": 70.2097195317106,\n","  \"best_exact_thresh\": -0.4838528633117676,\n","  \"best_f1\": 73.23017703457947,\n","  \"best_f1_thresh\": -0.17512845993041992\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W_-heQVOogr5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehYVPf8soi5j"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT2LjEnhojDQ"},"source":[""],"execution_count":null,"outputs":[]}]}